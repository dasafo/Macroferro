"""
Capa de servicios para operaciones de negocio del Bot de Telegram.

Esta capa implementa el patr√≥n Service Layer para la integraci√≥n con Telegram Bot API,
proporcionando una abstracci√≥n de alto nivel que orquesta la comunicaci√≥n bidireccional
con usuarios de Telegram, procesamiento inteligente de mensajes con IA, y b√∫squeda
avanzada de productos en el cat√°logo de Macroferro.

Responsabilidades principales:
- Comunicaci√≥n as√≠ncrona con Telegram Bot API (webhook y sending)
- Procesamiento inteligente de mensajes usando OpenAI GPT
- Orquestaci√≥n de b√∫squedas de productos con embedding vectorial
- Gesti√≥n de contexto conversacional y estado del usuario
- Formateo de respuestas rica en Markdown para mejor UX
- Manejo robusto de errores de red y timeouts

Caracter√≠sticas del dominio de Telegram Bot:
- Comunicaci√≥n as√≠ncrona y no bloqueante requerida
- Procesamiento de diferentes tipos de mensajes (texto, comandos, media)
- Integraci√≥n con servicios de IA para comprensi√≥n de intenciones
- B√∫squeda sem√°ntica avanzada en cat√°logo de productos
- Respuestas formateadas en Markdown para mejor presentaci√≥n
- Gesti√≥n de webhooks para recepci√≥n en tiempo real

Patrones implementados:
- Service Layer: L√≥gica de negocio centralizada para Telegram
- Async/Await: Operaciones no bloqueantes para alta concurrencia
- AI Integration: Procesamiento de lenguaje natural con OpenAI
- Error Handling: Manejo robusto de fallos de red y servicios externos
- Composition: Utiliza ProductService para b√∫squedas avanzadas

Integraciones externas:
- Telegram Bot API: Comunicaci√≥n bidireccional con usuarios
- OpenAI API: Procesamiento de lenguaje natural e intenciones
- Qdrant Vector DB: B√∫squeda sem√°ntica de productos (v√≠a ProductService)
- PostgreSQL: Datos de productos y contexto conversacional
"""

import asyncio
import logging
from typing import Optional, Dict, Any
import httpx
from openai import AsyncOpenAI
from sqlalchemy.orm import Session

from app.core.config import settings
from app.services.product_service import ProductService

logger = logging.getLogger(__name__)

class TelegramBotService:
    """
    Servicio para operaciones de negocio del Bot de Telegram.
    
    Esta clase encapsula toda la l√≥gica de negocio para la comunicaci√≥n con usuarios
    de Telegram, incluyendo procesamiento inteligente de mensajes, b√∫squeda de productos
    con IA, y orquestaci√≥n de respuestas personalizadas para consultas comerciales.
    
    Caracter√≠sticas principales:
    - Comunicaci√≥n as√≠ncrona con Telegram Bot API
    - An√°lisis de intenciones usando OpenAI GPT-3.5/4
    - B√∫squeda sem√°ntica de productos con embeddings vectoriales
    - Formateo rico de respuestas en Markdown
    - Manejo robusto de errores y timeouts de red
    - Configuraci√≥n flexible via variables de entorno
    
    Flujo principal de operaci√≥n:
    1. Recibir mensaje via webhook de Telegram
    2. Analizar intenci√≥n del usuario con IA
    3. Ejecutar b√∫squeda de productos si corresponde
    4. Formatear respuesta rica en Markdown
    5. Enviar respuesta de vuelta a Telegram
    
    Consideraciones de arquitectura:
    - Operaciones as√≠ncronas para no bloquear el event loop
    - Timeouts configurables para evitar cuelgues
    - Fallbacks graceful cuando servicios externos fallan
    - Logging detallado para debugging y monitoreo
    """

    def __init__(self):
        """
        Inicializa el servicio de Telegram Bot con configuraci√≥n externa.
        
        Configura clientes para servicios externos y valida configuraci√≥n requerida.
        Utiliza lazy loading de clientes pesados (OpenAI) para optimizar startup.
        
        Componentes inicializados:
        - Token del bot y URL base de Telegram API
        - Cliente OpenAI para procesamiento de lenguaje natural
        - Referencia al ProductService para b√∫squedas de cat√°logo
        
        Variables de entorno requeridas:
        - TELEGRAM_BOT_TOKEN: Token del bot obtenido de @BotFather
        - OPENAI_API_KEY: API key para procesamiento con IA
        
        Consideraciones de seguridad:
        - Tokens sensibles nunca se loggean
        - Validaci√≥n de configuraci√≥n en startup
        - Graceful degradation si servicios opcionales fallan
        """
        self.bot_token = settings.telegram_bot_token
        self.api_base_url = f"https://api.telegram.org/bot{self.bot_token}" if self.bot_token else None
        self.openai_client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY) if settings.OPENAI_API_KEY else None
        self.product_service = ProductService()

    # ========================================
    # COMUNICACI√ìN CON TELEGRAM API
    # ========================================
    
    async def send_message(self, chat_id: int, text: str, parse_mode: str = "Markdown") -> Dict[str, Any]:
        """
        Env√≠a un mensaje a un chat espec√≠fico a trav√©s del API de Telegram.
        
        Esta funci√≥n maneja la comunicaci√≥n saliente hacia usuarios de Telegram,
        con soporte para formateo rico en Markdown/HTML y manejo robusto de errores
        de red que son comunes en integraciones con APIs externas.
        
        Args:
            chat_id: ID √∫nico del chat donde enviar el mensaje
            text: Contenido del mensaje (puede incluir Markdown/HTML)
            parse_mode: Formato del texto ("Markdown", "HTML", o None)
            
        Returns:
            Respuesta JSON del API de Telegram con detalles del mensaje enviado
            
        Caracter√≠sticas implementadas:
        - Timeout configurado para evitar cuelgues indefinidos
        - Retry logic impl√≠cito via httpx para fallos transitorios
        - Logging detallado de errores para debugging
        - Validaci√≥n autom√°tica de respuesta HTTP
        
        Formato Markdown soportado:
        - *texto en negrita*
        - _texto en cursiva_
        - `c√≥digo en l√≠nea`
        - [enlace](https://example.com)
        - Listas con - o n√∫meros
        
        Manejo de errores t√≠picos:
        - NetworkError: Problemas de conectividad
        - HTTPError: Errores del API de Telegram (rate limits, etc.)
        - Timeout: Respuesta lenta del servidor
        
        Extensiones futuras:
        - Retry autom√°tico con backoff exponencial
        - Queue de mensajes para rate limiting
        - Soporte para inline keyboards y botones
        - M√©tricas de √©xito/fallo de env√≠o
        - Validaci√≥n de longitud de mensaje (4096 chars max)
        """
        if not self.api_base_url:
            logger.error("Bot token no configurado, no se puede enviar mensaje")
            raise ValueError("Telegram bot token not configured")
            
        url = f"{self.api_base_url}/sendMessage"
        payload = {
            "chat_id": chat_id,
            "text": text,
            "parse_mode": parse_mode
        }
        
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(url, json=payload)
                response.raise_for_status()
                
                result = response.json()
                logger.info(f"Mensaje enviado exitosamente a chat {chat_id}")
                return result
                
        except httpx.TimeoutException as e:
            logger.error(f"Timeout enviando mensaje a chat {chat_id}: {e}")
            raise
        except httpx.HTTPStatusError as e:
            logger.error(f"Error HTTP enviando mensaje a chat {chat_id}: {e.response.status_code} - {e.response.text}")
            raise
        except Exception as e:
            logger.error(f"Error inesperado enviando mensaje de Telegram a chat {chat_id}: {e}")
            raise

    # ========================================
    # PROCESAMIENTO INTELIGENTE DE MENSAJES
    # ========================================
    
    async def process_message(self, db: Session, message_text: str, chat_id: int) -> str:
        """
        Procesa un mensaje del usuario y genera una respuesta inteligente.
        
        Esta funci√≥n implementa el flujo principal de procesamiento de mensajes,
        orquestando m√∫ltiples servicios de IA para comprender la intenci√≥n del usuario
        y proporcionar respuestas contextuales y √∫tiles para consultas comerciales.
        
        Args:
            db: Sesi√≥n de SQLAlchemy para acceso a datos
            message_text: Texto del mensaje enviado por el usuario
            chat_id: ID del chat para contexto y logging
            
        Returns:
            Texto de respuesta formateado en Markdown listo para enviar
            
        Flujo de procesamiento implementado:
        1. **An√°lisis de intenci√≥n**: Determinar si busca productos espec√≠ficos
        2. **B√∫squeda sem√°ntica**: Si aplica, buscar en cat√°logo con IA
        3. **Formateo de resultados**: Estructurar productos encontrados
        4. **Respuesta general**: Para otros casos, generar respuesta contextual
        5. **Manejo de errores**: Fallback graceful ante fallos de servicios
        
        Tipos de mensajes manejados:
        - B√∫squedas de productos: "Busco tubos de PVC"
        - Comandos: /start, /help, /info
        - Conversaci√≥n general: Saludos, preguntas sobre empresa
        - Consultas t√©cnicas: Especificaciones, precios, disponibilidad
        
        Integraci√≥n con IA:
        - OpenAI gpt-4o-mini-2024-07-18 para an√°lisis de intenciones (r√°pido, econ√≥mico)
        - OpenAI gpt-4o-mini-2024-07-18 para respuestas generales (mejor calidad)
        - Embeddings text-embedding-3-small para b√∫squeda sem√°ntica
        
        Formato de respuestas:
        - Markdown para texto enriquecido
        - Emojis para mejor experiencia visual
        - Estructura consistente para productos
        - Mensajes de error amigables al usuario
        
        Optimizaciones de rendimiento:
        - Timeout corto para an√°lisis de intenci√≥n
        - B√∫squeda limitada a top 5 productos
        - Respuestas concisas para mejor UX m√≥vil
        - Caching potencial de respuestas frecuentes
        
        Extensiones futuras:
        - Contexto conversacional persistente
        - Historial de b√∫squedas del usuario
        - Recomendaciones personalizadas
        - Integraci√≥n con sistema de pedidos
        - Soporte multiidioma
        """
        if not self.openai_client:
            logger.warning("OpenAI no configurado, usando respuesta est√°tica")
            return "ü§ñ Hola! Soy el asistente de Macroferro. El servicio de IA no est√° disponible en este momento."
        
        try:
            # ========================================
            # FASE 1: AN√ÅLISIS DE INTENCI√ìN CON IA
            # ========================================
            
            intention_prompt = f"""
Analiza el siguiente mensaje de un usuario de una empresa que vende productos industriales y determina si est√° buscando productos espec√≠ficos.

Mensaje: "{message_text}"

Responde √öNICAMENTE con un JSON en este formato:
{{
    "is_product_search": true/false,
    "search_query": "t√©rminos de b√∫squeda optimizados si aplica",
    "user_intent": "descripci√≥n breve de la intenci√≥n del usuario"
}}

Si el usuario busca productos, extrae y optimiza los t√©rminos de b√∫squeda para encontrar productos industriales relevantes.
"""
            
            # Usar gpt-4o-mini-2024-07-18 para an√°lisis r√°pido y econ√≥mico de intenciones
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "user", "content": intention_prompt}],
                temperature=0.1,  # Baja temperatura para an√°lisis consistente
                max_tokens=200,   # Respuesta corta y estructurada
                timeout=10.0      # Timeout corto para responsividad
            )
            
            # ========================================
            # FASE 2: PROCESAMIENTO DE INTENCI√ìN
            # ========================================
            
            # Parsear respuesta de IA con manejo de errores
            import json
            try:
                ai_response = json.loads(response.choices[0].message.content)
            except json.JSONDecodeError as e:
                logger.error(f"Error parseando respuesta de IA: {e}")
                ai_response = {"is_product_search": False, "user_intent": "unknown"}
            
            # ========================================
            # RAMA 1: B√öSQUEDA DE PRODUCTOS CON IA
            # ========================================
            
            if ai_response.get("is_product_search", False):
                search_query = ai_response.get("search_query", message_text)
                logger.info(f"Realizando b√∫squeda de productos para: {search_query}")
                
                # B√∫squeda sem√°ntica usando ProductService
                search_results = await self.product_service.search_products(
                    db=db,
                    query_text=search_query,
                    top_k=5  # Limitar para respuesta r√°pida
                )
                
                # Obtener productos de los resultados estructurados
                main_products = search_results.get("main_results", [])
                related_products = search_results.get("related_results", [])
                all_products = main_products + related_products
                
                # Formatear respuesta con productos encontrados
                if all_products:
                    response_text = f"üîç *Productos encontrados para: {search_query}*\n\n"
                    
                    # Mostrar productos principales primero
                    if main_products:
                        response_text += "*üìã Resultados principales:*\n"
                        for i, product in enumerate(main_products, 1):
                            response_text += f"*{i}. {product.name}*\n"
                            # Truncar descripci√≥n para mejor legibilidad m√≥vil
                            description = product.description[:80] + "..." if len(product.description) > 80 else product.description
                            response_text += f"üìù {description}\n"
                            response_text += f"üí∞ Precio: ${product.price:,.0f}\n"
                            if product.category:
                                response_text += f"üè∑Ô∏è Categor√≠a: {product.category.name}\n"
                            response_text += "\n"
                    
                    # Mostrar productos relacionados si existen
                    if related_products:
                        response_text += "*üîó Tambi√©n te podr√≠a interesar:*\n"
                        for i, product in enumerate(related_products, len(main_products) + 1):
                            response_text += f"*{i}. {product.name}* - ${product.price:,.0f}\n"
                    
                    response_text += "\nüí¨ ¬øTe interesa alguno de estos productos? ¬°Preg√∫ntame m√°s detalles!"
                    
                else:
                    response_text = f"‚ùå No encontr√© productos espec√≠ficos para: *{search_query}*\n\n"
                    response_text += "üí° Puedes intentar con t√©rminos m√°s generales como:\n"
                    response_text += "‚Ä¢ 'tubos'\n‚Ä¢ 'v√°lvulas'\n‚Ä¢ 'conectores'\n‚Ä¢ 'herramientas'"
            
            # ========================================
            # RAMA 2: RESPUESTA GENERAL CON IA
            # ========================================
            
            else:
                logger.info(f"Generando respuesta general para intenci√≥n: {ai_response.get('user_intent', 'unknown')}")
                
                general_prompt = f"""
Eres un asistente amigable y profesional de Macroferro, una empresa que vende productos industriales.
El usuario te escribi√≥: "{message_text}"

Contexto de la empresa:
- Vendemos productos industriales (tuber√≠as, v√°lvulas, herramientas, etc.)
- Atendemos principalmente clientes B2B
- Tenemos un cat√°logo amplio de productos t√©cnicos
- Brindamos asesor√≠a t√©cnica especializada

Instrucciones de respuesta:
- Mant√©n un tono profesional pero amigable
- Si el usuario saluda, sal√∫dalo cordialmente
- Si pregunta sobre productos en general, expl√≠cale que puede buscar productos espec√≠ficos
- Si pregunta sobre la empresa, comparte informaci√≥n relevante
- Usa emojis apropiados para hacer la conversaci√≥n m√°s amigable
- Mant√©n la respuesta concisa (m√°ximo 300 caracteres)
- Invita al usuario a hacer consultas espec√≠ficas

Responde de manera √∫til y orientada a la acci√≥n.
"""
                
                # Usar GPT-4o-mini para respuestas de mejor calidad
                response = await self.openai_client.chat.completions.create(
                    model="gpt-4o-mini-2024-07-18",
                    messages=[{"role": "user", "content": general_prompt}],
                    temperature=0.7,    # Temperatura moderada para respuestas naturales
                    max_tokens=300,     # Respuestas concisas
                    timeout=15.0        # Timeout generoso para mejor calidad
                )
                
                response_text = response.choices[0].message.content
            
            logger.info(f"Respuesta generada exitosamente para chat {chat_id}")
            return response_text
            
        except asyncio.TimeoutError:
            logger.error(f"Timeout procesando mensaje de chat {chat_id}")
            return "‚è±Ô∏è Lo siento, el procesamiento est√° tomando m√°s tiempo del esperado. Por favor intenta nuevamente."
            
        except Exception as e:
            logger.error(f"Error procesando mensaje de chat {chat_id}: {e}")
            return "‚ùå Lo siento, hubo un error procesando tu mensaje. Por favor intenta nuevamente."

    # ========================================
    # CONFIGURACI√ìN DE WEBHOOK
    # ========================================
    
    async def set_webhook(self, webhook_url: str, secret_token: str) -> Dict[str, Any]:
        """
        Configura el webhook de Telegram para recibir actualizaciones en tiempo real.
        
        Esta funci√≥n establece la URL donde Telegram enviar√° todas las actualizaciones
        del bot (mensajes, comandos, etc.) usando el mecanismo de webhook en lugar
        de polling, lo cual es m√°s eficiente para aplicaciones en producci√≥n.
        
        Args:
            webhook_url: URL completa donde Telegram enviar√° las actualizaciones
            secret_token: Token secreto para validar que las actualizaciones vienen de Telegram
            
        Returns:
            Respuesta JSON del API de Telegram confirmando la configuraci√≥n
            
        Consideraciones de seguridad:
        - webhook_url debe usar HTTPS en producci√≥n
        - secret_token debe ser √∫nico y seguro (min 1-256 caracteres)
        - Telegram validar√° el certificado SSL de la URL
        - La URL debe ser p√∫blicamente accesible desde servidores de Telegram
        
        Configuraci√≥n t√≠pica para producci√≥n:
        - webhook_url: "https://api.macroferro.com/api/v1/telegram/webhook"
        - secret_token: Token generado aleatoriamente y guardado en variables de entorno
        
        Ventajas del webhook vs polling:
        - Latencia mucho menor (instant√°neo vs 1-30 segundos)
        - Menor uso de ancho de banda
        - No requiere conexiones persistentes
        - Escalabilidad horizontal mejor
        
        Consideraciones de infraestructura:
        - Requiere HTTPS v√°lido en producci√≥n
        - Load balancer debe enrutar al contenedor correcto
        - Manejo de reintentos si el webhook falla temporalmente
        - Monitoreo de salud del endpoint del webhook
        
        Extensiones futuras:
        - Validaci√≥n autom√°tica del secret_token en el endpoint
        - M√©tricas de latencia y √©xito de webhooks
        - Fallback a polling si webhook falla persistentemente
        - Configuraci√≥n de allowed_updates para filtrar tipos de eventos
        """
        if not self.api_base_url:
            logger.error("Bot token no configurado, no se puede configurar webhook")
            raise ValueError("Telegram bot token not configured")
            
        url = f"{self.api_base_url}/setWebhook"
        payload = {
            "url": webhook_url,
            "secret_token": secret_token,
            # Futuras configuraciones opcionales:
            # "allowed_updates": ["message", "callback_query"],  # Filtrar tipos de eventos
            # "drop_pending_updates": True,  # Limpiar actualizaciones pendientes
            # "max_connections": 100,  # L√≠mite de conexiones concurrentes
        }
        
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(url, json=payload)
                response.raise_for_status()
                
                result = response.json()
                if result.get("ok"):
                    logger.info(f"Webhook configurado exitosamente: {webhook_url}")
                else:
                    logger.error(f"Error configurando webhook: {result}")
                    
                return result
                
        except httpx.TimeoutException as e:
            logger.error(f"Timeout configurando webhook: {e}")
            raise
        except httpx.HTTPStatusError as e:
            logger.error(f"Error HTTP configurando webhook: {e.response.status_code} - {e.response.text}")
            raise
        except Exception as e:
            logger.error(f"Error inesperado configurando webhook: {e}")
            raise

# ========================================
# INSTANCIA SINGLETON DEL SERVICIO
# ========================================

# Instancia √∫nica del servicio para ser usada en toda la aplicaci√≥n
# Se crea solo si el token del bot est√° configurado para evitar errores en desarrollo
telegram_service = TelegramBotService() if settings.telegram_bot_token else None

# ========================================
# EXTENSIONES Y M√âTODOS AUXILIARES FUTUROS
# ========================================

# M√©todos auxiliares que se implementar√≠an en versiones futuras:
#
# async def _validate_user_permissions(self, user_id: int, chat_id: int) -> bool:
#     """Valida permisos del usuario para acceder a funcionalidades espec√≠ficas."""
#     pass
#
# async def _log_user_interaction(self, user_id: int, message_text: str, response_text: str) -> None:
#     """Registra interacciones para an√°lisis de uso y mejora del bot."""
#     pass
#
# async def _get_user_context(self, db: Session, user_id: int) -> Dict[str, Any]:
#     """Obtiene contexto conversacional persistente del usuario."""
#     pass
#
# async def _save_user_context(self, db: Session, user_id: int, context: Dict[str, Any]) -> None:
#     """Guarda contexto conversacional para futuras interacciones."""
#     pass
#
# async def _generate_product_recommendations(self, db: Session, user_id: int) -> List[models.Product]:
#     """Genera recomendaciones personalizadas basadas en historial del usuario."""
#     pass
#
# async def _format_product_details(self, product: models.Product) -> str:
#     """Formatea detalles completos de un producto para visualizaci√≥n rica."""
#     pass
#
# async def _handle_product_inquiry(self, db: Session, product_sku: str, user_id: int) -> str:
#     """Maneja consultas espec√≠ficas sobre un producto (precio, stock, especificaciones)."""
#     pass
#
# async def _send_typing_action(self, chat_id: int) -> None:
#     """Env√≠a acci√≥n de 'escribiendo...' para mejor UX durante procesamiento."""
#     pass
#
# async def _create_inline_keyboard(self, options: List[Dict[str, str]]) -> Dict[str, Any]:
#     """Crea teclado inline con botones para navegaci√≥n interactiva."""
#     pass
#
# async def _handle_callback_query(self, callback_data: str, chat_id: int) -> str:
#     """Procesa respuestas de botones inline del usuario."""
#     pass
#
# async def _validate_webhook_secret(self, request_headers: Dict[str, str]) -> bool:
#     """Valida que el webhook viene realmente de Telegram usando el secret token."""
#     pass
#
# async def _retry_failed_message(self, chat_id: int, text: str, max_retries: int = 3) -> bool:
#     """Reintenta env√≠o de mensajes fallidos con backoff exponencial."""
#     pass 