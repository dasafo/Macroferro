"""
Capa de servicios para operaciones de negocio del Bot de Telegram.

Esta capa implementa el patr√≥n Service Layer para la integraci√≥n con Telegram Bot API,
proporcionando una abstracci√≥n de alto nivel que orquesta la comunicaci√≥n bidireccional
con usuarios de Telegram, procesamiento inteligente de mensajes con IA, y b√∫squeda
avanzada de productos en el cat√°logo de Macroferro.

Responsabilidades principales:
- Comunicaci√≥n as√≠ncrona con Telegram Bot API (webhook y sending)
- Procesamiento inteligente de mensajes usando OpenAI GPT
- Orquestaci√≥n de b√∫squedas de productos con embedding vectorial
- Gesti√≥n de contexto conversacional y estado del usuario
- Formateo de respuestas rica en Markdown para mejor UX
- Manejo robusto de errores de red y timeouts

Caracter√≠sticas del dominio de Telegram Bot:
- Comunicaci√≥n as√≠ncrona y no bloqueante requerida
- Procesamiento de diferentes tipos de mensajes (texto, comandos, media)
- Integraci√≥n con servicios de IA para comprensi√≥n de intenciones
- B√∫squeda sem√°ntica avanzada en cat√°logo de productos
- Respuestas formateadas en Markdown para mejor presentaci√≥n
- Gesti√≥n de webhooks para recepci√≥n en tiempo real

Patrones implementados:
- Service Layer: L√≥gica de negocio centralizada para Telegram
- Async/Await: Operaciones no bloqueantes para alta concurrencia
- AI Integration: Procesamiento de lenguaje natural con OpenAI
- Error Handling: Manejo robusto de fallos de red y servicios externos
- Composition: Utiliza ProductService para b√∫squedas avanzadas

Integraciones externas:
- Telegram Bot API: Comunicaci√≥n bidireccional con usuarios
- OpenAI API: Procesamiento de lenguaje natural e intenciones
- Qdrant Vector DB: B√∫squeda sem√°ntica de productos (v√≠a ProductService)
- PostgreSQL: Datos de productos y contexto conversacional
"""

import asyncio
import logging
import json
from typing import Optional, Dict, Any, List
import httpx
from openai import AsyncOpenAI
from sqlalchemy.orm import Session
import re
import os

from app.core.config import settings
from app.services.product_service import ProductService
from app.crud.product_crud import get_product_by_sku, get_products

logger = logging.getLogger(__name__)

class TelegramBotService:
    """
    Servicio para operaciones de negocio del Bot de Telegram.
    
    Esta clase encapsula toda la l√≥gica de negocio para la comunicaci√≥n con usuarios
    de Telegram, incluyendo procesamiento inteligente de mensajes, b√∫squeda de productos
    con IA, y orquestaci√≥n de respuestas personalizadas para consultas comerciales.
    
    Caracter√≠sticas principales:
    - Comunicaci√≥n as√≠ncrona con Telegram Bot API
    - An√°lisis de intenciones usando OpenAI GPT-3.5/4
    - B√∫squeda sem√°ntica de productos con embeddings vectoriales
    - Formateo rico de respuestas en Markdown
    - Divisi√≥n inteligente de respuestas largas en m√∫ltiples mensajes
    - Manejo robusto de errores y timeouts de red
    - Configuraci√≥n flexible via variables de entorno
    
    Flujo principal de operaci√≥n:
    1. Recibir mensaje via webhook de Telegram
    2. Analizar intenci√≥n del usuario con IA
    3. Ejecutar b√∫squeda de productos si corresponde
    4. Formatear respuesta rica en Markdown
    5. Dividir respuesta en mensajes naturales
    6. Enviar mensajes secuencialmente a Telegram
    
    Consideraciones de arquitectura:
    - Operaciones as√≠ncronas para no bloquear el event loop
    - Timeouts configurables para evitar cuelgues
    - Fallbacks graceful cuando servicios externos fallan
    - Logging detallado para debugging y monitoreo
    """

    def __init__(self):
        """
        Inicializa el servicio de Telegram Bot con configuraci√≥n desde variables de entorno.
        
        Configura:
        - Cliente OpenAI para procesamiento de IA
        - URL base del API de Telegram
        - Servicio de productos para b√∫squedas
        - Logging para monitoreo
        
        Variables de entorno requeridas:
        - TELEGRAM_BOT_TOKEN: Token del bot de Telegram
        - OPENAI_API_KEY: API key de OpenAI
        
        Raises:
            ValueError: Si faltan configuraciones cr√≠ticas
        """
        # Configurar cliente OpenAI
        if settings.OPENAI_API_KEY:
            self.openai_client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
            logger.info("Cliente OpenAI configurado exitosamente")
        else:
            self.openai_client = None
            logger.warning("OpenAI API key no configurado - funciones de IA limitadas")
        
        # Configurar API de Telegram
        if settings.telegram_bot_token:
            self.api_base_url = f"https://api.telegram.org/bot{settings.telegram_bot_token}"
            logger.info("API de Telegram configurado exitosamente")
        else:
            self.api_base_url = None
            logger.warning("Telegram bot token no configurado")
        
        # Inicializar servicio de productos
        self.product_service = ProductService()
        logger.info("Servicio de productos inicializado")

    # ========================================
    # COMUNICACI√ìN CON TELEGRAM API
    # ========================================
    
    async def send_message(self, chat_id: int, text: str, parse_mode: str = "Markdown") -> Dict[str, Any]:
        """
        Env√≠a un mensaje a un chat espec√≠fico a trav√©s del API de Telegram.
        
        Esta funci√≥n maneja la comunicaci√≥n saliente hacia usuarios de Telegram,
        con soporte para formateo rico en Markdown/HTML y manejo robusto de errores
        de red que son comunes en integraciones con APIs externas.
        
        Args:
            chat_id: ID √∫nico del chat donde enviar el mensaje
            text: Contenido del mensaje (puede incluir Markdown/HTML)
            parse_mode: Formato del texto ("Markdown", "HTML", o None)
            
        Returns:
            Respuesta JSON del API de Telegram con detalles del mensaje enviado
            
        Caracter√≠sticas implementadas:
        - Timeout configurado para evitar cuelgues indefinidos
        - Retry logic impl√≠cito via httpx para fallos transitorios
        - Logging detallado de errores para debugging
        - Validaci√≥n autom√°tica de respuesta HTTP
        
        Formato Markdown soportado:
        - *texto en negrita*
        - _texto en cursiva_
        - `c√≥digo en l√≠nea`
        - [enlace](https://example.com)
        - Listas con - o n√∫meros
        
        Manejo de errores t√≠picos:
        - NetworkError: Problemas de conectividad
        - HTTPError: Errores del API de Telegram (rate limits, etc.)
        - Timeout: Respuesta lenta del servidor
        
        Extensiones futuras:
        - Retry autom√°tico con backoff exponencial
        - Queue de mensajes para rate limiting
        - Soporte para inline keyboards y botones
        - M√©tricas de √©xito/fallo de env√≠o
        - Validaci√≥n de longitud de mensaje (4096 chars max)
        """
        if not self.api_base_url:
            logger.error("Bot token no configurado, no se puede enviar mensaje")
            raise ValueError("Telegram bot token not configured")
            
        url = f"{self.api_base_url}/sendMessage"
        payload = {
            "chat_id": chat_id,
            "text": text,
            "parse_mode": parse_mode
        }
        
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(url, json=payload)
                response.raise_for_status()
                
                result = response.json()
                logger.info(f"Mensaje enviado exitosamente a chat {chat_id}")
                return result
                
        except httpx.TimeoutException as e:
            logger.error(f"Timeout enviando mensaje a chat {chat_id}: {e}")
            raise
        except httpx.HTTPStatusError as e:
            logger.error(f"Error HTTP enviando mensaje a chat {chat_id}: {e.response.status_code} - {e.response.text}")
            raise
        except Exception as e:
            logger.error(f"Error inesperado enviando mensaje de Telegram a chat {chat_id}: {e}")
            raise

    async def send_photo(self, chat_id: int, photo_url: str, caption: str = "", parse_mode: str = "Markdown") -> Dict[str, Any]:
        """
        Env√≠a una foto a un chat espec√≠fico a trav√©s del API de Telegram.
        
        Esta funci√≥n permite enviar im√°genes directamente desde URLs, con soporte
        para captions formateados y manejo robusto de errores espec√≠ficos de im√°genes.
        
        Args:
            chat_id: ID √∫nico del chat donde enviar la foto
            photo_url: URL de la imagen a enviar (debe ser accesible p√∫blicamente)
            caption: Texto descriptivo de la imagen (opcional, m√°ximo 1024 caracteres)
            parse_mode: Formato del caption ("Markdown", "HTML", o None)
            
        Returns:
            Respuesta JSON del API de Telegram con detalles de la foto enviada
            
        Caracter√≠sticas:
        - Soporte para URLs p√∫blicas de im√°genes
        - Caption con formato Markdown/HTML
        - Validaci√≥n autom√°tica de formato de imagen
        - Manejo espec√≠fico de errores de media
        
        Formatos de imagen soportados por Telegram:
        - JPG, PNG, GIF, BMP, WEBP
        - Tama√±o m√°ximo: 10MB para fotos
        - Resoluci√≥n m√°xima: 1280x1280 p√≠xeles
        
        Limitaciones del caption:
        - M√°ximo 1024 caracteres
        - Mismo formato Markdown que mensajes de texto
        
        Casos de uso:
        - Mostrar im√°genes de productos en cat√°logo
        - Enviar fotos de referencia t√©cnica
        - Compartir diagramas o esquemas
        
        Manejo de errores espec√≠ficos:
        - URL inaccesible o imagen corrupta
        - Formato de imagen no soportado
        - Imagen demasiado grande
        - Problemas de conectividad
        """
        if not self.api_base_url:
            logger.error("Bot token no configurado, no se puede enviar foto")
            raise ValueError("Telegram bot token not configured")
            
        url = f"{self.api_base_url}/sendPhoto"
        payload = {
            "chat_id": chat_id,
            "photo": photo_url,
            "caption": caption,
            "parse_mode": parse_mode
        }
        
        try:
            async with httpx.AsyncClient(timeout=45.0) as client:  # Timeout m√°s largo para im√°genes
                response = await client.post(url, json=payload)
                response.raise_for_status()
                
                result = response.json()
                logger.info(f"Foto enviada exitosamente a chat {chat_id} desde URL: {photo_url}")
                return result
                
        except httpx.TimeoutException as e:
            logger.error(f"Timeout enviando foto a chat {chat_id} desde {photo_url}: {e}")
            raise
        except httpx.HTTPStatusError as e:
            logger.error(f"Error HTTP enviando foto a chat {chat_id} desde {photo_url}: {e.response.status_code} - {e.response.text}")
            # Los errores comunes incluyen:
            # - 400 Bad Request: URL de imagen inv√°lida o inaccesible
            # - 413 Payload Too Large: Imagen demasiado grande
            # - 415 Unsupported Media Type: Formato no soportado
            raise
        except Exception as e:
            logger.error(f"Error inesperado enviando foto de Telegram a chat {chat_id} desde {photo_url}: {e}")
            raise

    async def send_multiple_messages(self, chat_id: int, messages: List[str], delay_between_messages: float = 1.0) -> List[Dict[str, Any]]:
        """
        Env√≠a m√∫ltiples mensajes de forma secuencial con delay entre cada uno.
        
        Esta funci√≥n simula una conversaci√≥n natural enviando mensajes en secuencia
        con pausas para que parezca que la persona est√° escribiendo cada respuesta.
        
        Args:
            chat_id: ID del chat donde enviar los mensajes
            messages: Lista de mensajes a enviar
            delay_between_messages: Tiempo en segundos entre mensajes
            
        Returns:
            Lista con las respuestas del API de Telegram para cada mensaje
        """
        results = []
        
        for i, message in enumerate(messages):
            if i > 0:  # No hacer delay antes del primer mensaje
                await asyncio.sleep(delay_between_messages)
            
            try:
                result = await self.send_message(chat_id, message)
                results.append(result)
                logger.info(f"Mensaje {i+1}/{len(messages)} enviado exitosamente")
            except Exception as e:
                logger.error(f"Error enviando mensaje {i+1}/{len(messages)}: {e}")
                # Continuar con los siguientes mensajes aunque uno falle
                results.append({"error": str(e)})
        
        return results

    async def send_product_with_image(self, chat_id: int, product, caption: str, additional_messages: List[str] = None, delay_between_messages: float = 1.5) -> List[Dict[str, Any]]:
        """
        Env√≠a informaci√≥n de un producto con su imagen (si est√° disponible) seguido de mensajes adicionales.
        
        Esta funci√≥n coordina el env√≠o de fotos de productos con informaci√≥n detallada,
        creando una experiencia visual rica para consultas espec√≠ficas de productos.
        
        Args:
            chat_id: ID del chat donde enviar la informaci√≥n
            product: Objeto Product con relaciones cargadas (categor√≠a, im√°genes)
            caption: Texto para acompa√±ar la imagen (informaci√≥n b√°sica del producto)
            additional_messages: Lista de mensajes adicionales a enviar despu√©s de la foto
            delay_between_messages: Tiempo en segundos entre mensajes
            
        Returns:
            Lista con las respuestas del API de Telegram para cada env√≠o
            
        Flujo de env√≠o:
        1. Si el producto tiene imagen: env√≠a foto con caption
        2. Si no tiene imagen: env√≠a mensaje de texto con informaci√≥n b√°sica
        3. Env√≠a mensajes adicionales con delay para simular conversaci√≥n natural
        
        Manejo de im√°genes:
        - Prioriza la primera imagen asociada al producto
        - Fallback graceful si la imagen no est√° disponible o falla
        - Caption limitado a 1024 caracteres (l√≠mite de Telegram)
        """
        results = []
        
        # Verificar si el producto tiene im√°genes asociadas
        has_image = False
        image_url = None
        
        if hasattr(product, 'images_association') and product.images_association:
            # Obtener la primera imagen asociada
            first_image_association = product.images_association[0]
            if hasattr(first_image_association, 'image') and first_image_association.image:
                image_url = str(first_image_association.image.url)
                has_image = True
                logger.info(f"Producto {product.sku} tiene imagen: {image_url}")
        
        # Limitar el caption a 1024 caracteres (l√≠mite de Telegram para fotos)
        truncated_caption = caption[:1020] + "..." if len(caption) > 1024 else caption
        
        try:
            if has_image and image_url:
                # Enviar foto con caption
                result = await self.send_photo(chat_id, image_url, truncated_caption)
                results.append(result)
                logger.info(f"Foto del producto {product.sku} enviada exitosamente")
            else:
                # Fallback: enviar como mensaje de texto si no hay imagen
                result = await self.send_message(chat_id, caption)
                results.append(result)
                logger.info(f"Informaci√≥n del producto {product.sku} enviada como texto (sin imagen)")
                
        except Exception as e:
            logger.error(f"Error enviando foto del producto {product.sku}: {e}")
            # Fallback: enviar como mensaje de texto
            try:
                result = await self.send_message(chat_id, caption)
                results.append(result)
                logger.info(f"Enviado como texto despu√©s de fallo de imagen para producto {product.sku}")
            except Exception as text_error:
                logger.error(f"Error enviando fallback de texto para producto {product.sku}: {text_error}")
                results.append({"error": str(text_error)})
        
        # Enviar mensajes adicionales con delay
        if additional_messages:
            for i, message in enumerate(additional_messages):
                await asyncio.sleep(delay_between_messages)
                
                try:
                    result = await self.send_message(chat_id, message)
                    results.append(result)
                    logger.info(f"Mensaje adicional {i+1}/{len(additional_messages)} enviado para producto {product.sku}")
                except Exception as e:
                    logger.error(f"Error enviando mensaje adicional {i+1} para producto {product.sku}: {e}")
                    results.append({"error": str(e)})
        
        return results

    def split_response_into_messages(self, response_text: str, max_length: int = 4000) -> List[str]:
        """
        Divide una respuesta larga en m√∫ltiples mensajes naturales.
        
        Esta funci√≥n analiza el contenido de la respuesta y la divide en puntos
        l√≥gicos para crear una conversaci√≥n m√°s natural y fluida.
        
        Args:
            response_text: Texto completo de la respuesta
            max_length: Longitud m√°xima por mensaje (l√≠mite de Telegram es 4096)
            
        Returns:
            Lista de mensajes divididos de forma natural
        """
        if len(response_text) <= max_length:
            return [response_text]
        
        messages = []
        
        # Dividir por secciones principales (marcadas con t√≠tulos en negrita)
        sections = re.split(r'\n\n(?=\*[^*]+\*)', response_text)
        
        current_message = ""
        
        for section in sections:
            # Si agregar esta secci√≥n excede el l√≠mite
            if len(current_message) + len(section) + 2 > max_length:  # +2 por \n\n
                if current_message:
                    messages.append(current_message.strip())
                    current_message = section
                else:
                    # La secci√≥n es muy larga, dividir por p√°rrafos
                    paragraphs = section.split('\n\n')
                    for paragraph in paragraphs:
                        if len(current_message) + len(paragraph) + 2 > max_length:
                            if current_message:
                                messages.append(current_message.strip())
                                current_message = paragraph
                            else:
                                # P√°rrafo muy largo, dividir por l√≠neas
                                lines = paragraph.split('\n')
                                for line in lines:
                                    if len(current_message) + len(line) + 1 > max_length:
                                        if current_message:
                                            messages.append(current_message.strip())
                                            current_message = line
                                        else:
                                            # L√≠nea muy larga, cortar por caracteres
                                            messages.append(line[:max_length-3] + "...")
                                    else:
                                        current_message += ("\n" if current_message else "") + line
                        else:
                            current_message += ("\n\n" if current_message else "") + paragraph
            else:
                current_message += ("\n\n" if current_message else "") + section
        
        if current_message:
            messages.append(current_message.strip())
        
        return messages

    # ========================================
    # PROCESAMIENTO INTELIGENTE DE MENSAJES
    # ========================================
    
    async def process_message(self, db: Session, message_text: str, chat_id: int) -> Dict[str, Any]:
        """
        Procesa un mensaje del usuario con inteligencia contextual avanzada.
        
        El bot ahora puede:
        1. Detectar referencias a productos espec√≠ficos (por nombre, marca, caracter√≠stica)
        2. Consultar detalles exactos de productos en la base de datos
        3. Proporcionar informaci√≥n t√©cnica espec√≠fica
        4. Mantener conversaciones naturales y contextuales
        5. Manejar m√∫ltiples tipos de consulta de forma inteligente
        6. Enviar fotos de productos cuando est√©n disponibles
        
        El procesamiento se hace con un LLM m√°s potente para mejor comprensi√≥n contextual.
        
        Returns:
            Dict con el tipo de respuesta y datos necesarios:
            - 'type': 'product_with_image' | 'text_messages'
            - 'messages': Lista de mensajes de texto (para text_messages)
            - 'product': Objeto producto (para product_with_image)
            - 'caption': Caption para la imagen (para product_with_image) 
            - 'additional_messages': Mensajes adicionales (para product_with_image)
        """
        if not self.openai_client:
            logger.warning("OpenAI no configurado, usando respuesta est√°tica")
            return {
                "type": "text_messages",
                "messages": ["ü§ñ Hola! Soy el asistente de Macroferro. El servicio de IA no est√° disponible en este momento."]
            }
        
        try:
            # ========================================
            # AN√ÅLISIS INTELIGENTE CON GPT-4
            # ========================================
            
            # Usar GPT-4 para un an√°lisis m√°s sofisticado de la intenci√≥n
            analysis_prompt = f"""
Eres un asistente de inteligencia artificial especializado en productos industriales de Macroferro.

Analiza este mensaje del usuario y determina exactamente qu√© tipo de respuesta necesita:

Mensaje del usuario: "{message_text}"

Contexto empresarial:
- Macroferro vende productos industriales: tubos, v√°lvulas, herramientas, conectores, tornillos, etc.
- Los clientes hacen consultas t√©cnicas espec√≠ficas sobre productos
- Los usuarios pueden estar preguntando por detalles de un producto que ya encontraron
- Tambi√©n pueden estar haciendo b√∫squedas nuevas de productos

IMPORTANTE: Si el usuario menciona un producto espec√≠fico (nombre, marca, o caracter√≠stica muy espec√≠fica), probablemente quiere informaci√≥n detallada de ESE producto, no una b√∫squeda general.

Responde √öNICAMENTE con este JSON:
{{
    "intent_type": "product_details" | "product_search" | "technical_question" | "general_conversation",
    "confidence": 0.8,
    "specific_product_mentioned": "nombre exacto del producto si se menciona" | null,
    "search_terms": ["t√©rmino1", "t√©rmino2"] | null,
    "technical_aspect": "aspecto t√©cnico espec√≠fico" | null,
    "user_intent_description": "descripci√≥n clara de lo que quiere el usuario",
    "suggested_response_tone": "informative" | "conversational" | "technical"
}}

Tipos de intent:
- "product_details": Usuario pregunta por un producto espec√≠fico que mencion√≥ por nombre
- "product_search": Usuario busca productos por categor√≠a/tipo general 
- "technical_question": Pregunta t√©cnica sobre especificaciones
- "general_conversation": Saludo, informaci√≥n general, otros temas

Ejemplos:
- "¬øQu√© especificaciones tiene el Esmalte para Exteriores Bahco?" ‚Üí product_details
- "Busco tubos de PVC" ‚Üí product_search  
- "¬øCu√°l es el di√°metro de ese tubo?" ‚Üí technical_question
- "Hola, ¬øc√≥mo est√°n?" ‚Üí general_conversation
"""
            
            # Usar gpt-4o-mini para an√°lisis m√°s sofisticado
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "user", "content": analysis_prompt}],
                temperature=0.1,
                max_tokens=300,
                timeout=15.0
            )
            
            # Procesar respuesta de IA
            try:
                ai_content = response.choices[0].message.content
                logger.info(f"An√°lisis de IA: {ai_content}")
                
                # Extraer JSON
                json_content = self._extract_json_from_markdown(ai_content)
                analysis = json.loads(json_content)
                logger.info(f"An√°lisis parseado: {analysis}")
                
            except json.JSONDecodeError as e:
                logger.error(f"Error parseando an√°lisis de IA: {e}")
                analysis = {"intent_type": "general_conversation", "confidence": 0.5}
            
            intent_type = analysis.get("intent_type", "general_conversation")
            confidence = analysis.get("confidence", 0.5)
            
            # ========================================
            # ENRUTAMIENTO INTELIGENTE SEG√öN INTENCI√ìN
            # ========================================
            
            if intent_type == "product_details":
                return await self._handle_specific_product_inquiry(db, analysis, message_text)
            
            elif intent_type == "product_search":
                messages = await self._handle_product_search(db, analysis, message_text)
                return {"type": "text_messages", "messages": messages}
            
            elif intent_type == "technical_question":
                messages = await self._handle_technical_question(db, analysis, message_text)
                return {"type": "text_messages", "messages": messages}
            
            else:  # general_conversation
                messages = await self._handle_conversational_response(message_text, analysis)
                return {"type": "text_messages", "messages": messages}
            
        except asyncio.TimeoutError:
            logger.error(f"Timeout procesando mensaje de chat {chat_id}")
            return {
                "type": "text_messages",
                "messages": ["‚è±Ô∏è Lo siento, el procesamiento est√° tomando m√°s tiempo del esperado. Por favor intenta nuevamente."]
            }
            
        except Exception as e:
            logger.error(f"Error procesando mensaje de chat {chat_id}: {e}")
            return {
                "type": "text_messages", 
                "messages": ["‚ùå Lo siento, hubo un error procesando tu mensaje. Por favor intenta nuevamente."]
            }

    def _extract_json_from_markdown(self, content: str) -> str:
        """Extrae JSON de bloques de c√≥digo markdown."""
        # Buscar bloques de c√≥digo JSON
        json_match = re.search(r'```json\s*\n(.*?)\n```', content, re.DOTALL)
        if json_match:
            return json_match.group(1).strip()
        
        # Buscar bloques de c√≥digo gen√©ricos
        code_match = re.search(r'```\s*\n(.*?)\n```', content, re.DOTALL)
        if code_match:
            return code_match.group(1).strip()
        
        # Si no hay bloques de c√≥digo, devolver el contenido original
        return content.strip()

    async def _handle_specific_product_inquiry(self, db: Session, analysis: Dict, message_text: str) -> Dict[str, Any]:
        """
        Maneja consultas sobre productos espec√≠ficos con b√∫squeda inteligente.
        
        Returns:
            Dict con tipo, producto y mensajes estructurados para el env√≠o
        """
        try:
            specific_product = analysis.get("specific_product_mentioned")
            if not specific_product:
                # Extraer posibles nombres de productos del mensaje
                # Buscar palabras clave de productos comunes
                search_terms = analysis.get("search_terms", [])
                if not search_terms:
                    search_terms = [message_text]
            else:
                search_terms = [specific_product]
            
            logger.info(f"Buscando producto espec√≠fico: {search_terms}")
            
            # 1. Intentar b√∫squeda exacta por SKU primero
            product = None
            for term in search_terms:
                # Intentar como SKU
                product = get_product_by_sku(db, term.upper())
                if product:
                    break
                    
                # Intentar b√∫squeda exacta por nombre
                products = get_products(db, name_like=term, limit=5)
                if products:
                    # Buscar coincidencia exacta
                    for p in products:
                        if p.name.lower() == term.lower():
                            product = p
                            break
                    
                    # Si no hay coincidencia exacta, tomar el primer resultado si es similar
                    if not product and products:
                        # Verificar si el primer resultado es suficientemente similar
                        first_product = products[0]
                        if term.lower() in first_product.name.lower() or first_product.name.lower() in term.lower():
                            product = first_product
                
                if product:
                    break
            
            # 2. Si no encontramos producto por b√∫squeda directa, usar b√∫squeda sem√°ntica
            if not product:
                logger.info("No se encontr√≥ producto directo, usando b√∫squeda sem√°ntica")
                search_results = await self.product_service.search_products(
                    db=db,
                    query_text=message_text,
                    top_k=3
                )
                
                main_products = search_results.get("main_results", [])
                if main_products:
                    # Solo tomar el mejor resultado si tiene alta similitud
                    product = main_products[0]
                    logger.info(f"Producto encontrado por b√∫squeda sem√°ntica: {product.name}")
            
            if product:
                # Generar respuesta detallada con imagen
                product_response = await self._generate_detailed_product_response(product, message_text)
                
                return {
                    "type": "product_with_image",
                    "product": product,
                    "caption": product_response["caption"],
                    "additional_messages": product_response["additional_messages"],
                    "messages": []  # No usado para este tipo
                }
            else:
                # No se encontr√≥ producto espec√≠fico
                return {
                    "type": "text_messages",
                    "messages": [
                        f"üîç Busqu√© informaci√≥n espec√≠fica sobre: *{message_text}*",
                        "‚ùå No pude encontrar ese producto espec√≠fico en nuestro cat√°logo.",
                        "üí° Intenta con:",
                        "‚Ä¢ Nombre m√°s espec√≠fico o marca del producto",
                        "‚Ä¢ C√≥digo SKU si lo tienes",
                        "‚Ä¢ Categor√≠a general (ej: 'herramientas', 'tubos', 'v√°lvulas')",
                        "üõ†Ô∏è ¬øTe puedo ayudar con alguna b√∫squeda m√°s general?"
                    ],
                    "product": None,
                    "caption": "",
                    "additional_messages": []
                }
            
        except Exception as e:
            logger.error(f"Error en consulta espec√≠fica de producto: {e}")
            return {
                "type": "text_messages",
                "messages": ["‚ùå Hubo un error buscando ese producto. ¬øPuedes intentar de nuevo?"],
                "product": None,
                "caption": "",
                "additional_messages": []
            }

    async def _generate_detailed_product_response(self, product, original_question: str) -> Dict[str, Any]:
        """
        Genera una respuesta conversacional y detallada sobre un producto espec√≠fico.
        
        Ahora retorna un diccionario con el caption para la imagen y mensajes adicionales
        para crear una experiencia visual rica con la foto del producto.
        
        Returns:
            Dict con 'caption' para la imagen y 'additional_messages' para env√≠o secuencial
        """
        # Preparar informaci√≥n del producto para el LLM
        product_info = {
            "sku": product.sku,
            "name": product.name,
            "description": product.description or "Sin descripci√≥n disponible",
            "price": float(product.price),
            "brand": product.brand or "Sin marca especificada",
            "category": product.category.name if product.category else "Sin categor√≠a",
            "specifications": product.spec_json or {}
        }
        
        # Prompt para generar respuesta conversacional inteligente
        response_prompt = f"""
Eres un asistente experto en productos industriales de Macroferro. Un cliente te pregunt√≥:

"{original_question}"

Y encontraste exactamente este producto en tu cat√°logo:

PRODUCTO ENCONTRADO:
- Nombre: {product_info['name']}
- SKU: {product_info['sku']}
- Descripci√≥n: {product_info['description']}
- Precio: ${product_info['price']:,.2f}
- Marca: {product_info['brand']}
- Categor√≠a: {product_info['category']}
- Especificaciones t√©cnicas: {json.dumps(product_info['specifications'], indent=2, ensure_ascii=False)}

INSTRUCCIONES:
Vas a enviar la informaci√≥n en dos partes:

1. CAPTION DE IMAGEN (m√°ximo 800 caracteres):
   - Informaci√≥n b√°sica y atractiva del producto
   - Incluye nombre, precio, marca de forma visual
   - Usa emojis apropiados
   - Debe ser conciso pero informativo

2. MENSAJES ADICIONALES (separa con "|||"):
   - Detalles t√©cnicos espec√≠ficos
   - Especificaciones importantes
   - Aplicaciones recomendadas
   - Invitaci√≥n a m√°s preguntas

Formato de respuesta:
CAPTION:
[Tu caption de m√°ximo 800 caracteres]

ADDITIONAL:
[Mensaje 1]|||[Mensaje 2]|||[Mensaje 3]

Usa *texto* para negrita, formato de lista con ‚Ä¢ para especificaciones, y emojis t√©cnicos apropiados.
Responde en espa√±ol de manera profesional y √∫til.
"""
        
        # Generar respuesta con LLM
        response = await self.openai_client.chat.completions.create(
            model="gpt-4o-mini-2024-07-18",
            messages=[{"role": "user", "content": response_prompt}],
            temperature=0.7,  # Temperatura moderada para naturalidad
            max_tokens=1000,   # Espacio para caption + mensajes adicionales
            timeout=20.0
        )
        
        response_text = response.choices[0].message.content
        
        # Separar caption y mensajes adicionales
        if "CAPTION:" in response_text and "ADDITIONAL:" in response_text:
            parts = response_text.split("ADDITIONAL:")
            caption = parts[0].replace("CAPTION:", "").strip()
            additional_text = parts[1].strip()
            
            # Dividir mensajes adicionales
            additional_messages = [msg.strip() for msg in additional_text.split("|||") if msg.strip()]
        else:
            # Fallback si el formato no es el esperado
            messages = self.split_response_into_messages(response_text, 800)
            caption = messages[0] if messages else f"*{product.name}*\nüí∞ ${product.price:,.2f}"
            additional_messages = messages[1:] if len(messages) > 1 else []
        
        return {
            "caption": caption,
            "additional_messages": additional_messages
        }

    async def _handle_product_search(self, db: Session, analysis: Dict, message_text: str) -> List[str]:
        """
        Maneja b√∫squedas generales de productos con respuesta conversacional.
        Aplica umbrales de similitud para evitar resultados irrelevantes.
        """
        search_terms = analysis.get("search_terms", [])
        
        # Asegurar que search_terms sea una lista
        if search_terms is None:
            search_terms = []
            
        search_query = " ".join(search_terms) if search_terms else message_text
        
        logger.info(f"Realizando b√∫squeda general de productos para: {search_query}")
        
        # B√∫squeda sem√°ntica usando ProductService con umbral moderado
        search_results = await self.product_service.search_products(
            db=db,
            query_text=search_query,
            top_k=8  # M√°s productos para mejor selecci√≥n
        )
        
        main_products = search_results.get("main_results", [])
        related_products = search_results.get("related_results", [])
        
        # Si no hay resultados con umbral bajo, definitivamente no hay nada relevante
        if not main_products and not related_products:
            return [
                f"üîç Busqu√© productos relacionados con: *{search_query}*",
                "‚ùå No encontr√© productos que coincidan con esa b√∫squeda en nuestro cat√°logo.",
                "üí° Te sugiero buscar con t√©rminos m√°s generales:",
                "‚Ä¢ **Herramientas**: taladros, llaves, destornilladores",
                "‚Ä¢ **Materiales**: tubos, v√°lvulas, conectores",
                "‚Ä¢ **Ferreter√≠a**: tornillos, tuercas, arandelas",
                "‚Ä¢ **Construcci√≥n**: cemento, pinturas, adhesivos",
                "üõ†Ô∏è ¬øHay alguna categor√≠a espec√≠fica que te interese?"
            ]
        
        # Si hay muy pocos resultados, ser m√°s cauteloso en la presentaci√≥n
        total_results = len(main_products) + len(related_products)
        if total_results <= 2:
            return [
                f"üîç Busqu√© productos para: *{search_query}*",
                f"‚ö†Ô∏è Solo encontr√© {total_results} producto(s) relacionado(s).",
                "Puede que la b√∫squeda sea muy espec√≠fica o el producto no est√© en nuestro cat√°logo.",
                "üí° ¬øPodr√≠as proporcionar m√°s detalles o usar t√©rminos m√°s generales?"
            ]
        
        messages = []
        
        # Mensaje inicial m√°s conversacional
        initial_message = f"üîç ¬°Perfecto! Encontr√© varios productos para tu b√∫squeda de *{search_query}*.\n\n‚ú® Aqu√≠ est√°n las mejores opciones:"
        messages.append(initial_message)
        
        # Mostrar productos principales de forma m√°s conversacional
        if main_products:
            for i, product in enumerate(main_products, 1):
                product_message = f"*{i}. {product.name}*\n"
                
                if product.description:
                    desc = product.description[:120] + "..." if len(product.description) > 120 else product.description
                    product_message += f"üìù {desc}\n\n"
                
                product_message += f"üí∞ Precio: *${product.price:,.0f}*\n"
                
                if product.category:
                    product_message += f"üè∑Ô∏è {product.category.name}\n"
                
                if hasattr(product, 'brand') and product.brand:
                    product_message += f"üè≠ {product.brand}\n"
                
                # Agregar especificaciones destacadas si existen
                if product.spec_json:
                    specs_preview = []
                    for key, value in list(product.spec_json.items())[:2]:  # Solo las primeras 2 specs
                        specs_preview.append(f"‚Ä¢ {key}: {value}")
                    if specs_preview:
                        product_message += f"‚öôÔ∏è Especificaciones:\n" + "\n".join(specs_preview) + "\n"
                
                messages.append(product_message)
        
        # Mostrar productos relacionados m√°s brevemente
        if related_products:
            related_message = "üîó *Tambi√©n podr√≠an interesarte:*\n\n"
            for product in related_products:
                related_message += f"‚Ä¢ *{product.name}* - ${product.price:,.0f}\n"
            messages.append(related_message)
        
        # Mensaje final conversacional
        follow_up = "üí¨ ¬øTe interesa conocer m√°s detalles de alguno de estos productos?\n\nüîç Solo menciona el nombre del producto y te dar√© informaci√≥n t√©cnica completa."
        messages.append(follow_up)
        
        return messages

    async def _handle_technical_question(self, db: Session, analysis: Dict, message_text: str) -> List[str]:
        """
        Maneja preguntas t√©cnicas espec√≠ficas sobre especificaciones de productos.
        
        Esta funci√≥n analiza preguntas t√©cnicas y trata de proporcionar respuestas
        precisas basadas en las especificaciones de productos relevantes.
        """
        search_terms = analysis.get("search_terms", [])
        technical_aspect = analysis.get("technical_aspect", "")
        
        # Asegurar que search_terms sea una lista
        if search_terms is None:
            search_terms = []
        
        # Si no hay t√©rminos de b√∫squeda espec√≠ficos, extraer del mensaje
        if not search_terms:
            search_terms = message_text.split()
        
        search_query = " ".join(search_terms) if search_terms else message_text
        
        logger.info(f"Analizando pregunta t√©cnica: {technical_aspect} para b√∫squeda: {search_query}")
        
        # Buscar productos relevantes para la pregunta t√©cnica
        search_results = await self.product_service.search_products(
            db=db,
            query_text=search_query,
            top_k=3  # Pocos productos pero relevantes
        )
        
        main_products = search_results.get("main_results", [])
        
        if not main_products:
            return [
                f"üîç Busqu√© informaci√≥n t√©cnica sobre: *{search_query}*",
                "‚ùå No encontr√© productos con especificaciones t√©cnicas espec√≠ficas para esa consulta.\n\nüí° ¬øPodr√≠as ser m√°s espec√≠fico sobre el producto que te interesa?"
            ]
        
        # Analizar especificaciones t√©cnicas con IA
        technical_analysis = await self._analyze_technical_specifications(
            main_products, 
            technical_aspect or message_text, 
            message_text
        )
        
        # Dividir respuesta t√©cnica en mensajes naturales
        messages = self.split_response_into_messages(technical_analysis, 3800)
        
        return messages

    async def _handle_conversational_response(self, message_text: str, analysis: Dict) -> List[str]:
        """
        Maneja respuestas conversacionales generales con personalidad de vendedor experto.
        """
        logger.info(f"Generando respuesta conversacional para: {analysis.get('user_intent_description', 'unknown')}")
        
        conversation_prompt = f"""
Eres un asistente especializado de Macroferro, una empresa que vende productos industriales de alta calidad.

El usuario te escribi√≥: "{message_text}"

CONTEXTO DE MACROFERRO:
- Vendemos productos industriales: tuber√≠as, v√°lvulas, herramientas el√©ctricas, conectores, tornillos, pinturas industriales, etc.
- Atendemos principalmente clientes profesionales (electricistas, plomeros, constructores, talleres)
- Tenemos un cat√°logo amplio con especificaciones t√©cnicas detalladas
- Brindamos asesor√≠a t√©cnica especializada
- Somos expertos en compatibilidad y aplicaciones de productos

TU PERSONALIDAD:
- Profesional pero amigable y conversacional
- Experto t√©cnico que conoce bien los productos
- Orientado a ayudar y resolver problemas
- Proactivo en sugerir soluciones

INSTRUCCIONES:
1. Responde de manera natural y conversacional
2. Si es un saludo, sal√∫dalo cordialmente y pres√©ntate como experto en productos industriales
3. Si pregunta sobre la empresa, comparte informaci√≥n relevante
4. Si la consulta es vaga, haz preguntas espec√≠ficas para ayudar mejor
5. Siempre orienta hacia productos espec√≠ficos cuando sea posible
6. Usa emojis apropiados para hacer la conversaci√≥n m√°s amigable
7. Divide en 2-3 mensajes si es necesario (separa con "|||")
8. Invita a hacer consultas espec√≠ficas sobre productos
9. Mant√©n un tono experto pero accesible

Responde de manera √∫til y orientada a la acci√≥n.
"""
        
        if not self.openai_client:
            # Respuesta est√°tica si no hay OpenAI configurado
            if any(greeting in message_text.lower() for greeting in ['hola', 'buenos', 'buenas', 'hello', 'hi', 'saludos']):
                return [
                    "¬°Hola! üëã Soy el asistente t√©cnico de Macroferro.",
                    "üîß Estoy aqu√≠ para ayudarte con informaci√≥n sobre nuestros productos industriales: tuber√≠as, v√°lvulas, herramientas, conectores, pinturas y m√°s.\n\nüí¨ ¬øEn qu√© puedo ayudarte hoy?"
                ]
            else:
                return [
                    "üëã ¬°Hola! Soy el asistente de Macroferro.",
                    "üîç Puedo ayudarte a encontrar productos industriales y responder preguntas t√©cnicas.\n\nüí° Prueba pregunt√°ndome por alg√∫n producto espec√≠fico o tipo de material que necesites."
                ]
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "user", "content": conversation_prompt}],
                temperature=0.8,    # Temperatura m√°s alta para conversaci√≥n natural
                max_tokens=500,
                timeout=15.0
            )
            
            response_text = response.choices[0].message.content
            
            # Dividir si incluye separador
            if "|||" in response_text:
                messages = [msg.strip() for msg in response_text.split("|||") if msg.strip()]
            else:
                messages = self.split_response_into_messages(response_text, 3800)
            
            return messages
            
        except Exception as e:
            logger.error(f"Error generando respuesta conversacional: {e}")
            return [
                "üëã ¬°Hola! Soy el asistente de Macroferro.",
                "üîç Estoy aqu√≠ para ayudarte con informaci√≥n sobre productos industriales.\n\nüí¨ ¬øEn qu√© puedo ayudarte?"
            ]

    # ========================================
    # AN√ÅLISIS T√âCNICO DE ESPECIFICACIONES
    # ========================================
    
    async def _analyze_technical_specifications(
        self, 
        products: List, 
        technical_aspect: str, 
        original_question: str
    ) -> str:
        """
        Analiza las especificaciones t√©cnicas de productos y genera respuesta inteligente.
        
        Esta funci√≥n examina el campo spec_json de cada producto para encontrar
        informaci√≥n t√©cnica relevante y generar respuestas detalladas usando IA.
        
        Args:
            products: Lista de productos relevantes encontrados
            technical_aspect: Aspecto t√©cnico espec√≠fico (di√°metro, presi√≥n, etc.)
            original_question: Pregunta original del usuario para contexto
            
        Returns:
            Respuesta formateada con informaci√≥n t√©cnica detallada
        """
        try:
            # Recopilar informaci√≥n t√©cnica de todos los productos
            technical_info = []
            for product in products:
                product_info = {
                    "name": product.name,
                    "sku": product.sku,
                    "brand": product.brand,
                    "category": product.category.name if product.category else "Sin categor√≠a",
                    "price": float(product.price),
                    "specifications": product.spec_json or {}
                }
                technical_info.append(product_info)
            
            # Crear prompt para an√°lisis t√©cnico con IA
            technical_prompt = f"""
El usuario pregunt√≥: "{original_question}"

Se identific√≥ que busca informaci√≥n sobre: {technical_aspect}

Aqu√≠ est√°n los productos relevantes con sus especificaciones t√©cnicas:

{json.dumps(technical_info, indent=2, ensure_ascii=False)}

Tu tarea es analizar estas especificaciones y responder la pregunta t√©cnica del usuario de manera clara y profesional.

Instrucciones:
1. Busca en las especificaciones (campo "specifications") informaci√≥n relacionada con la pregunta
2. Si encuentras datos relevantes, pres√©ntalos de forma clara y organizada
3. Compara entre productos si hay m√∫ltiples opciones
4. Si no hay informaci√≥n espec√≠fica en las especificaciones, ind√≠calo honestamente
5. Usa formato Markdown para mejor presentaci√≥n
6. Incluye emojis t√©cnicos apropiados (‚öôÔ∏è üìê üîß üíß ‚ö° etc.)
7. Mant√©n un tono profesional pero accesible
8. Si es posible, da recomendaciones basadas en la informaci√≥n disponible

Responde en espa√±ol de manera concisa pero completa.
"""
            
            # Generar respuesta t√©cnica con IA
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "user", "content": technical_prompt}],
                temperature=0.3,    # Baja temperatura para precisi√≥n t√©cnica
                max_tokens=800,     # M√°s espacio para respuestas t√©cnicas detalladas
                timeout=20.0        # Timeout generoso para an√°lisis complejo
            )
            
            ai_response = response.choices[0].message.content
            
            # Agregar footer con productos analizados
            footer = f"\n\n*üìã Productos analizados:*\n"
            for i, product in enumerate(products, 1):
                footer += f"{i}. {product.name} (SKU: {product.sku})\n"
            
            footer += "\nüí¨ ¬øNecesitas m√°s detalles espec√≠ficos de alg√∫n producto?"
            
            return ai_response + footer
            
        except Exception as e:
            logger.error(f"Error analizando especificaciones t√©cnicas: {e}")
            
            # Fallback: respuesta b√°sica con informaci√≥n disponible
            response_text = f"üîß *Informaci√≥n t√©cnica encontrada:*\n\n"
            
            for i, product in enumerate(products, 1):
                response_text += f"*{i}. {product.name}*\n"
                response_text += f"üì¶ SKU: {product.sku}\n"
                if product.brand:
                    response_text += f"üè≠ Marca: {product.brand}\n"
                if product.category:
                    response_text += f"üè∑Ô∏è Categor√≠a: {product.category.name}\n"
                
                # Mostrar especificaciones si existen
                if product.spec_json:
                    response_text += f"‚öôÔ∏è *Especificaciones disponibles:*\n"
                    for key, value in product.spec_json.items():
                        response_text += f"  ‚Ä¢ {key}: {value}\n"
                else:
                    response_text += f"üìù No hay especificaciones t√©cnicas detalladas disponibles\n"
                
                response_text += "\n"
            
            response_text += "üí¨ Para informaci√≥n t√©cnica m√°s espec√≠fica, puedes contactar directamente con nuestro equipo t√©cnico."
            
            return response_text

    # ========================================
    # CONFIGURACI√ìN DE WEBHOOK
    # ========================================
    
    async def set_webhook(self, webhook_url: str, secret_token: str) -> Dict[str, Any]:
        """
        Configura el webhook de Telegram para recibir actualizaciones en tiempo real.
        
        Esta funci√≥n establece la URL donde Telegram enviar√° todas las actualizaciones
        del bot (mensajes, comandos, etc.) usando el mecanismo de webhook en lugar
        de polling, lo cual es m√°s eficiente para aplicaciones en producci√≥n.
        
        Args:
            webhook_url: URL completa donde Telegram enviar√° las actualizaciones
            secret_token: Token secreto para validar que las actualizaciones vienen de Telegram
            
        Returns:
            Respuesta JSON del API de Telegram confirmando la configuraci√≥n
            
        Consideraciones de seguridad:
        - webhook_url debe usar HTTPS en producci√≥n
        - secret_token debe ser √∫nico y seguro (min 1-256 caracteres)
        - Telegram validar√° el certificado SSL de la URL
        - La URL debe ser p√∫blicamente accesible desde servidores de Telegram
        
        Configuraci√≥n t√≠pica para producci√≥n:
        - webhook_url: "https://api.macroferro.com/api/v1/telegram/webhook"
        - secret_token: Token generado aleatoriamente y guardado en variables de entorno
        
        Ventajas del webhook vs polling:
        - Latencia mucho menor (instant√°neo vs 1-30 segundos)
        - Menor uso de ancho de banda
        - No requiere conexiones persistentes
        - Escalabilidad horizontal mejor
        
        Consideraciones de infraestructura:
        - Requiere HTTPS v√°lido en producci√≥n
        - Load balancer debe enrutar al contenedor correcto
        - Manejo de reintentos si el webhook falla temporalmente
        - Monitoreo de salud del endpoint del webhook
        
        Extensiones futuras:
        - Validaci√≥n autom√°tica del secret_token en el endpoint
        - M√©tricas de latencia y √©xito de webhooks
        - Fallback a polling si webhook falla persistentemente
        - Configuraci√≥n de allowed_updates para filtrar tipos de eventos
        """
        if not self.api_base_url:
            logger.error("Bot token no configurado, no se puede configurar webhook")
            raise ValueError("Telegram bot token not configured")
            
        url = f"{self.api_base_url}/setWebhook"
        payload = {
            "url": webhook_url,
            "secret_token": secret_token,
            # Futuras configuraciones opcionales:
            # "allowed_updates": ["message", "callback_query"],  # Filtrar tipos de eventos
            # "drop_pending_updates": True,  # Limpiar actualizaciones pendientes
            # "max_connections": 100,  # L√≠mite de conexiones concurrentes
        }
        
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(url, json=payload)
                response.raise_for_status()
                
                result = response.json()
                if result.get("ok"):
                    logger.info(f"Webhook configurado exitosamente: {webhook_url}")
                else:
                    logger.error(f"Error configurando webhook: {result}")
                    
                return result
                
        except httpx.TimeoutException as e:
            logger.error(f"Timeout configurando webhook: {e}")
            raise
        except httpx.HTTPStatusError as e:
            logger.error(f"Error HTTP configurando webhook: {e.response.status_code} - {e.response.text}")
            raise
        except Exception as e:
            logger.error(f"Error inesperado configurando webhook: {e}")
            raise

# ========================================
# INSTANCIA SINGLETON DEL SERVICIO
# ========================================

# Instancia √∫nica del servicio para ser usada en toda la aplicaci√≥n
# Se crea solo si el token del bot est√° configurado para evitar errores en desarrollo
telegram_service = TelegramBotService() if settings.telegram_bot_token else None

# ========================================
# EXTENSIONES Y M√âTODOS AUXILIARES FUTUROS
# ========================================

# M√©todos auxiliares que se implementar√≠an en versiones futuras:
#
# async def _validate_user_permissions(self, user_id: int, chat_id: int) -> bool:
#     """Valida permisos del usuario para acceder a funcionalidades espec√≠ficas."""
#     pass
#
# async def _log_user_interaction(self, user_id: int, message_text: str, response_text: str) -> None:
#     """Registra interacciones para an√°lisis de uso y mejora del bot."""
#     pass
#
# async def _get_user_context(self, db: Session, user_id: int) -> Dict[str, Any]:
#     """Obtiene contexto conversacional persistente del usuario."""
#     pass
#
# async def _save_user_context(self, db: Session, user_id: int, context: Dict[str, Any]) -> None:
#     """Guarda contexto conversacional para futuras interacciones."""
#     pass
#
# async def _generate_product_recommendations(self, db: Session, user_id: int) -> List[models.Product]:
#     """Genera recomendaciones personalizadas basadas en historial del usuario."""
#     pass
#
# async def _format_product_details(self, product: models.Product) -> str:
#     """Formatea detalles completos de un producto para visualizaci√≥n rica."""
#     pass
#
# async def _handle_product_inquiry(self, db: Session, product_sku: str, user_id: int) -> str:
#     """Maneja consultas espec√≠ficas sobre un producto (precio, stock, especificaciones)."""
#     pass
#
# async def _send_typing_action(self, chat_id: int) -> None:
#     """Env√≠a acci√≥n de 'escribiendo...' para mejor UX durante procesamiento."""
#     pass
#
# async def _create_inline_keyboard(self, options: List[Dict[str, str]]) -> Dict[str, Any]:
#     """Crea teclado inline con botones para navegaci√≥n interactiva."""
#     pass
#
# async def _handle_callback_query(self, callback_data: str, chat_id: int) -> str:
#     """Procesa respuestas de botones inline del usuario."""
#     pass
#
# async def _validate_webhook_secret(self, request_headers: Dict[str, str]) -> bool:
#     """Valida que el webhook viene realmente de Telegram usando el secret token."""
#     pass
#
# async def _retry_failed_message(self, chat_id: int, text: str, max_retries: int = 3) -> bool:
#     """Reintenta env√≠o de mensajes fallidos con backoff exponencial."""
#     pass 