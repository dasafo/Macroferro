"""
Capa de servicios para operaciones de negocio del Bot de Telegram.

Esta capa implementa el patr√≥n Service Layer para la integraci√≥n con Telegram Bot API,
proporcionando una abstracci√≥n de alto nivel que orquesta la comunicaci√≥n bidireccional
con usuarios de Telegram, procesamiento inteligente de mensajes con IA, y b√∫squeda
avanzada de productos en el cat√°logo de Macroferro.

Responsabilidades principales:
- Comunicaci√≥n as√≠ncrona con Telegram Bot API (webhook y sending)
- Procesamiento inteligente de mensajes usando OpenAI GPT
- Orquestaci√≥n de b√∫squedas de productos con embedding vectorial
- Gesti√≥n de contexto conversacional y estado del usuario
- Formateo de respuestas rica en Markdown para mejor UX
- Manejo robusto de errores de red y timeouts

Caracter√≠sticas del dominio de Telegram Bot:
- Comunicaci√≥n as√≠ncrona y no bloqueante requerida
- Procesamiento de diferentes tipos de mensajes (texto, comandos, media)
- Integraci√≥n con servicios de IA para comprensi√≥n de intenciones
- B√∫squeda sem√°ntica avanzada en cat√°logo de productos
- Respuestas formateadas en Markdown para mejor presentaci√≥n
- Gesti√≥n de webhooks para recepci√≥n en tiempo real

Patrones implementados:
- Service Layer: L√≥gica de negocio centralizada para Telegram
- Async/Await: Operaciones no bloqueantes para alta concurrencia
- AI Integration: Procesamiento de lenguaje natural con OpenAI
- Error Handling: Manejo robusto de fallos de red y servicios externos
- Composition: Utiliza ProductService para b√∫squedas avanzadas

Integraciones externas:
- Telegram Bot API: Comunicaci√≥n bidireccional con usuarios
- OpenAI API: Procesamiento de lenguaje natural e intenciones
- Qdrant Vector DB: B√∫squeda sem√°ntica de productos (v√≠a ProductService)
- PostgreSQL: Datos de productos y contexto conversacional
"""

import asyncio
import logging
import json
from typing import Optional, Dict, Any, List
import httpx
from openai import AsyncOpenAI
from sqlalchemy.orm import Session
import re
import os

from app.core.config import settings
from app.services.product_service import ProductService

logger = logging.getLogger(__name__)

class TelegramBotService:
    """
    Servicio para operaciones de negocio del Bot de Telegram.
    
    Esta clase encapsula toda la l√≥gica de negocio para la comunicaci√≥n con usuarios
    de Telegram, incluyendo procesamiento inteligente de mensajes, b√∫squeda de productos
    con IA, y orquestaci√≥n de respuestas personalizadas para consultas comerciales.
    
    Caracter√≠sticas principales:
    - Comunicaci√≥n as√≠ncrona con Telegram Bot API
    - An√°lisis de intenciones usando OpenAI GPT-3.5/4
    - B√∫squeda sem√°ntica de productos con embeddings vectoriales
    - Formateo rico de respuestas en Markdown
    - Divisi√≥n inteligente de respuestas largas en m√∫ltiples mensajes
    - Manejo robusto de errores y timeouts de red
    - Configuraci√≥n flexible via variables de entorno
    
    Flujo principal de operaci√≥n:
    1. Recibir mensaje via webhook de Telegram
    2. Analizar intenci√≥n del usuario con IA
    3. Ejecutar b√∫squeda de productos si corresponde
    4. Formatear respuesta rica en Markdown
    5. Dividir respuesta en mensajes naturales
    6. Enviar mensajes secuencialmente a Telegram
    
    Consideraciones de arquitectura:
    - Operaciones as√≠ncronas para no bloquear el event loop
    - Timeouts configurables para evitar cuelgues
    - Fallbacks graceful cuando servicios externos fallan
    - Logging detallado para debugging y monitoreo
    """

    def __init__(self):
        """
        Inicializa el servicio de Telegram Bot con configuraci√≥n desde variables de entorno.
        
        Configura:
        - Cliente OpenAI para procesamiento de IA
        - URL base del API de Telegram
        - Servicio de productos para b√∫squedas
        - Logging para monitoreo
        
        Variables de entorno requeridas:
        - TELEGRAM_BOT_TOKEN: Token del bot de Telegram
        - OPENAI_API_KEY: API key de OpenAI
        
        Raises:
            ValueError: Si faltan configuraciones cr√≠ticas
        """
        # Configurar cliente OpenAI
        if settings.OPENAI_API_KEY:
            self.openai_client = AsyncOpenAI(api_key=settings.OPENAI_API_KEY)
            logger.info("Cliente OpenAI configurado exitosamente")
        else:
            self.openai_client = None
            logger.warning("OpenAI API key no configurado - funciones de IA limitadas")
        
        # Configurar API de Telegram
        if settings.telegram_bot_token:
            self.api_base_url = f"https://api.telegram.org/bot{settings.telegram_bot_token}"
            logger.info("API de Telegram configurado exitosamente")
        else:
            self.api_base_url = None
            logger.warning("Telegram bot token no configurado")
        
        # Inicializar servicio de productos
        self.product_service = ProductService()
        logger.info("Servicio de productos inicializado")

    # ========================================
    # COMUNICACI√ìN CON TELEGRAM API
    # ========================================
    
    async def send_message(self, chat_id: int, text: str, parse_mode: str = "Markdown") -> Dict[str, Any]:
        """
        Env√≠a un mensaje a un chat espec√≠fico a trav√©s del API de Telegram.
        
        Esta funci√≥n maneja la comunicaci√≥n saliente hacia usuarios de Telegram,
        con soporte para formateo rico en Markdown/HTML y manejo robusto de errores
        de red que son comunes en integraciones con APIs externas.
        
        Args:
            chat_id: ID √∫nico del chat donde enviar el mensaje
            text: Contenido del mensaje (puede incluir Markdown/HTML)
            parse_mode: Formato del texto ("Markdown", "HTML", o None)
            
        Returns:
            Respuesta JSON del API de Telegram con detalles del mensaje enviado
            
        Caracter√≠sticas implementadas:
        - Timeout configurado para evitar cuelgues indefinidos
        - Retry logic impl√≠cito via httpx para fallos transitorios
        - Logging detallado de errores para debugging
        - Validaci√≥n autom√°tica de respuesta HTTP
        
        Formato Markdown soportado:
        - *texto en negrita*
        - _texto en cursiva_
        - `c√≥digo en l√≠nea`
        - [enlace](https://example.com)
        - Listas con - o n√∫meros
        
        Manejo de errores t√≠picos:
        - NetworkError: Problemas de conectividad
        - HTTPError: Errores del API de Telegram (rate limits, etc.)
        - Timeout: Respuesta lenta del servidor
        
        Extensiones futuras:
        - Retry autom√°tico con backoff exponencial
        - Queue de mensajes para rate limiting
        - Soporte para inline keyboards y botones
        - M√©tricas de √©xito/fallo de env√≠o
        - Validaci√≥n de longitud de mensaje (4096 chars max)
        """
        if not self.api_base_url:
            logger.error("Bot token no configurado, no se puede enviar mensaje")
            raise ValueError("Telegram bot token not configured")
            
        url = f"{self.api_base_url}/sendMessage"
        payload = {
            "chat_id": chat_id,
            "text": text,
            "parse_mode": parse_mode
        }
        
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(url, json=payload)
                response.raise_for_status()
                
                result = response.json()
                logger.info(f"Mensaje enviado exitosamente a chat {chat_id}")
                return result
                
        except httpx.TimeoutException as e:
            logger.error(f"Timeout enviando mensaje a chat {chat_id}: {e}")
            raise
        except httpx.HTTPStatusError as e:
            logger.error(f"Error HTTP enviando mensaje a chat {chat_id}: {e.response.status_code} - {e.response.text}")
            raise
        except Exception as e:
            logger.error(f"Error inesperado enviando mensaje de Telegram a chat {chat_id}: {e}")
            raise

    async def send_multiple_messages(self, chat_id: int, messages: List[str], delay_between_messages: float = 1.0) -> List[Dict[str, Any]]:
        """
        Env√≠a m√∫ltiples mensajes de forma secuencial con delay entre cada uno.
        
        Esta funci√≥n simula una conversaci√≥n natural enviando mensajes en secuencia
        con pausas para que parezca que la persona est√° escribiendo cada respuesta.
        
        Args:
            chat_id: ID del chat donde enviar los mensajes
            messages: Lista de mensajes a enviar
            delay_between_messages: Tiempo en segundos entre mensajes
            
        Returns:
            Lista con las respuestas del API de Telegram para cada mensaje
        """
        results = []
        
        for i, message in enumerate(messages):
            if i > 0:  # No hacer delay antes del primer mensaje
                await asyncio.sleep(delay_between_messages)
            
            try:
                result = await self.send_message(chat_id, message)
                results.append(result)
                logger.info(f"Mensaje {i+1}/{len(messages)} enviado exitosamente")
            except Exception as e:
                logger.error(f"Error enviando mensaje {i+1}/{len(messages)}: {e}")
                # Continuar con los siguientes mensajes aunque uno falle
                results.append({"error": str(e)})
        
        return results

    def split_response_into_messages(self, response_text: str, max_length: int = 4000) -> List[str]:
        """
        Divide una respuesta larga en m√∫ltiples mensajes naturales.
        
        Esta funci√≥n analiza el contenido de la respuesta y la divide en puntos
        l√≥gicos para crear una conversaci√≥n m√°s natural y fluida.
        
        Args:
            response_text: Texto completo de la respuesta
            max_length: Longitud m√°xima por mensaje (l√≠mite de Telegram es 4096)
            
        Returns:
            Lista de mensajes divididos de forma natural
        """
        if len(response_text) <= max_length:
            return [response_text]
        
        messages = []
        
        # Dividir por secciones principales (marcadas con t√≠tulos en negrita)
        sections = re.split(r'\n\n(?=\*[^*]+\*)', response_text)
        
        current_message = ""
        
        for section in sections:
            # Si agregar esta secci√≥n excede el l√≠mite
            if len(current_message) + len(section) + 2 > max_length:  # +2 por \n\n
                if current_message:
                    messages.append(current_message.strip())
                    current_message = section
                else:
                    # La secci√≥n es muy larga, dividir por p√°rrafos
                    paragraphs = section.split('\n\n')
                    for paragraph in paragraphs:
                        if len(current_message) + len(paragraph) + 2 > max_length:
                            if current_message:
                                messages.append(current_message.strip())
                                current_message = paragraph
                            else:
                                # P√°rrafo muy largo, dividir por l√≠neas
                                lines = paragraph.split('\n')
                                for line in lines:
                                    if len(current_message) + len(line) + 1 > max_length:
                                        if current_message:
                                            messages.append(current_message.strip())
                                            current_message = line
                                        else:
                                            # L√≠nea muy larga, cortar por caracteres
                                            messages.append(line[:max_length-3] + "...")
                                    else:
                                        current_message += ("\n" if current_message else "") + line
                        else:
                            current_message += ("\n\n" if current_message else "") + paragraph
            else:
                current_message += ("\n\n" if current_message else "") + section
        
        if current_message:
            messages.append(current_message.strip())
        
        return messages

    # ========================================
    # PROCESAMIENTO INTELIGENTE DE MENSAJES
    # ========================================
    
    async def process_message(self, db: Session, message_text: str, chat_id: int) -> List[str]:
        """
        Procesa un mensaje del usuario con inteligencia contextual avanzada.
        
        El bot ahora puede:
        1. Detectar referencias a productos espec√≠ficos (por nombre, marca, caracter√≠stica)
        2. Consultar detalles exactos de productos en la base de datos
        3. Proporcionar informaci√≥n t√©cnica espec√≠fica
        4. Mantener conversaciones naturales y contextuales
        5. Manejar m√∫ltiples tipos de consulta de forma inteligente
        
        El procesamiento se hace con un LLM m√°s potente para mejor comprensi√≥n contextual.
        """
        if not self.openai_client:
            logger.warning("OpenAI no configurado, usando respuesta est√°tica")
            return ["ü§ñ Hola! Soy el asistente de Macroferro. El servicio de IA no est√° disponible en este momento."]
        
        try:
            # ========================================
            # AN√ÅLISIS INTELIGENTE CON GPT-4
            # ========================================
            
            # Usar GPT-4 para un an√°lisis m√°s sofisticado de la intenci√≥n
            analysis_prompt = f"""
Eres un asistente de inteligencia artificial especializado en productos industriales de Macroferro.

Analiza este mensaje del usuario y determina exactamente qu√© tipo de respuesta necesita:

Mensaje del usuario: "{message_text}"

Contexto empresarial:
- Macroferro vende productos industriales: tubos, v√°lvulas, herramientas, conectores, tornillos, etc.
- Los clientes hacen consultas t√©cnicas espec√≠ficas sobre productos
- Los usuarios pueden estar preguntando por detalles de un producto que ya encontraron
- Tambi√©n pueden estar haciendo b√∫squedas nuevas de productos

IMPORTANTE: Si el usuario menciona un producto espec√≠fico (nombre, marca, o caracter√≠stica muy espec√≠fica), probablemente quiere informaci√≥n detallada de ESE producto, no una b√∫squeda general.

Responde √öNICAMENTE con este JSON:
{{
    "intent_type": "product_details" | "product_search" | "technical_question" | "general_conversation",
    "confidence": 0.8,
    "specific_product_mentioned": "nombre exacto del producto si se menciona" | null,
    "search_terms": ["t√©rmino1", "t√©rmino2"] | null,
    "technical_aspect": "aspecto t√©cnico espec√≠fico" | null,
    "user_intent_description": "descripci√≥n clara de lo que quiere el usuario",
    "suggested_response_tone": "informative" | "conversational" | "technical"
}}

Tipos de intent:
- "product_details": Usuario pregunta por un producto espec√≠fico que mencion√≥ por nombre
- "product_search": Usuario busca productos por categor√≠a/tipo general 
- "technical_question": Pregunta t√©cnica sobre especificaciones
- "general_conversation": Saludo, informaci√≥n general, otros temas

Ejemplos:
- "¬øQu√© especificaciones tiene el Esmalte para Exteriores Bahco?" ‚Üí product_details
- "Busco tubos de PVC" ‚Üí product_search  
- "¬øCu√°l es el di√°metro de ese tubo?" ‚Üí technical_question
- "Hola, ¬øc√≥mo est√°n?" ‚Üí general_conversation
"""
            
            # Usar gpt-4o-mini para an√°lisis m√°s sofisticado
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "user", "content": analysis_prompt}],
                temperature=0.1,
                max_tokens=300,
                timeout=15.0
            )
            
            # Procesar respuesta de IA
            try:
                ai_content = response.choices[0].message.content
                logger.info(f"An√°lisis de IA: {ai_content}")
                
                # Extraer JSON
                json_content = self._extract_json_from_markdown(ai_content)
                analysis = json.loads(json_content)
                logger.info(f"An√°lisis parseado: {analysis}")
                
            except json.JSONDecodeError as e:
                logger.error(f"Error parseando an√°lisis de IA: {e}")
                analysis = {"intent_type": "general_conversation", "confidence": 0.5}
            
            intent_type = analysis.get("intent_type", "general_conversation")
            confidence = analysis.get("confidence", 0.5)
            
            # ========================================
            # ENRUTAMIENTO INTELIGENTE SEG√öN INTENCI√ìN
            # ========================================
            
            if intent_type == "product_details":
                return await self._handle_specific_product_inquiry(db, analysis, message_text)
            
            elif intent_type == "product_search":
                return await self._handle_product_search(db, analysis, message_text)
            
            elif intent_type == "technical_question":
                return await self._handle_technical_question(db, analysis, message_text)
            
            else:  # general_conversation
                return await self._handle_conversational_response(message_text, analysis)
            
        except asyncio.TimeoutError:
            logger.error(f"Timeout procesando mensaje de chat {chat_id}")
            return ["‚è±Ô∏è Lo siento, el procesamiento est√° tomando m√°s tiempo del esperado. Por favor intenta nuevamente."]
            
        except Exception as e:
            logger.error(f"Error procesando mensaje de chat {chat_id}: {e}")
            return ["‚ùå Lo siento, hubo un error procesando tu mensaje. Por favor intenta nuevamente."]

    def _extract_json_from_markdown(self, content: str) -> str:
        """Extrae JSON de bloques de c√≥digo markdown."""
        # Buscar bloques de c√≥digo JSON
        json_match = re.search(r'```json\s*\n(.*?)\n```', content, re.DOTALL)
        if json_match:
            return json_match.group(1).strip()
        
        # Buscar bloques de c√≥digo gen√©ricos
        code_match = re.search(r'```\s*\n(.*?)\n```', content, re.DOTALL)
        if code_match:
            return code_match.group(1).strip()
        
        # Si no hay bloques de c√≥digo, devolver el contenido original
        return content.strip()

    async def _handle_specific_product_inquiry(self, db: Session, analysis: Dict, message_text: str) -> List[str]:
        """
        Maneja consultas espec√≠ficas sobre un producto particular.
        
        Esta funci√≥n busca primero por nombre exacto, luego por nombre parcial,
        y proporciona informaci√≥n detallada del producto espec√≠fico.
        """
        specific_product = analysis.get("specific_product_mentioned")
        search_terms = analysis.get("search_terms", [])
        
        # Asegurar que search_terms sea una lista
        if search_terms is None:
            search_terms = []
        
        if specific_product:
            search_terms.insert(0, specific_product)
        
        logger.info(f"Buscando informaci√≥n espec√≠fica de producto: {search_terms}")
        
        # Intentar encontrar el producto espec√≠fico por nombre
        found_product = None
        
        # 1. Buscar por nombre exacto en la base de datos
        for term in search_terms:
            if not term:
                continue
                
            # Buscar por nombre parcial en la base de datos
            from app.crud import product_crud
            products = product_crud.get_products(
                db=db, 
                name_like=term.strip(),
                limit=1  # Solo necesitamos el primer resultado exacto
            )
            
            if products:
                found_product = products[0]
                logger.info(f"Producto encontrado por nombre: {found_product.name}")
                break
        
        # 2. Si no se encontr√≥ por nombre exacto, usar b√∫squeda sem√°ntica
        if not found_product and search_terms:
            search_query = " ".join(search_terms)
            search_results = await self.product_service.search_products(
                db=db,
                query_text=search_query,
                top_k=1  # Solo el m√°s relevante
            )
            
            main_results = search_results.get("main_results", [])
            if main_results:
                found_product = main_results[0]
                logger.info(f"Producto encontrado por b√∫squeda sem√°ntica: {found_product.name}")
        
        if not found_product:
            return [
                "üîç Hmm, no encontr√© informaci√≥n espec√≠fica sobre ese producto.",
                "üí° ¬øPodr√≠as ser m√°s espec√≠fico con el nombre o modelo?\n\nTambi√©n puedo ayudarte a buscar productos si me dices qu√© tipo de producto necesitas."
            ]
        
        # ========================================
        # GENERAR RESPUESTA DETALLADA DEL PRODUCTO
        # ========================================
        
        return await self._generate_detailed_product_response(found_product, message_text)

    async def _generate_detailed_product_response(self, product, original_question: str) -> List[str]:
        """
        Genera una respuesta conversacional y detallada sobre un producto espec√≠fico.
        """
        # Preparar informaci√≥n del producto para el LLM
        product_info = {
            "sku": product.sku,
            "name": product.name,
            "description": product.description or "Sin descripci√≥n disponible",
            "price": float(product.price),
            "brand": product.brand or "Sin marca especificada",
            "category": product.category.name if product.category else "Sin categor√≠a",
            "specifications": product.spec_json or {}
        }
        
        # Prompt para generar respuesta conversacional inteligente
        response_prompt = f"""
Eres un asistente experto en productos industriales de Macroferro. Un cliente te pregunt√≥:

"{original_question}"

Y encontraste exactamente este producto en tu cat√°logo:

PRODUCTO ENCONTRADO:
- Nombre: {product_info['name']}
- SKU: {product_info['sku']}
- Descripci√≥n: {product_info['description']}
- Precio: ${product_info['price']:,.2f}
- Marca: {product_info['brand']}
- Categor√≠a: {product_info['category']}
- Especificaciones t√©cnicas: {json.dumps(product_info['specifications'], indent=2, ensure_ascii=False)}

INSTRUCCIONES:
1. Responde de forma conversacional y natural, como un vendedor experto que conoce bien el producto
2. Enf√≥cate en lo que el cliente pregunt√≥ espec√≠ficamente
3. Proporciona informaci√≥n t√©cnica relevante de las especificaciones si las hay
4. Menciona aplicaciones t√≠picas y beneficios del producto
5. Incluye el precio de forma natural en la conversaci√≥n
6. Si hay especificaciones t√©cnicas, res√°ltalas de forma clara
7. Mant√©n un tono profesional pero amigable
8. Usa emojis apropiados para hacer la respuesta m√°s visual
9. Divide la respuesta en 2-3 mensajes naturales si es necesario (separa con "|||")
10. Termina invitando a hacer m√°s preguntas espec√≠ficas

Formato de respuesta:
- Usa *texto* para negrita
- Usa formato de lista con ‚Ä¢ para especificaciones
- Incluye emojis t√©cnicos apropiados (üîß ‚öôÔ∏è üìê üíß ‚ö° üèóÔ∏è etc.)

Responde en espa√±ol de manera profesional y √∫til.
"""
        
        # Generar respuesta con LLM
        response = await self.openai_client.chat.completions.create(
            model="gpt-4o-mini-2024-07-18",
            messages=[{"role": "user", "content": response_prompt}],
            temperature=0.7,  # Temperatura moderada para naturalidad
            max_tokens=800,   # Espacio suficiente para respuesta detallada
            timeout=20.0
        )
        
        response_text = response.choices[0].message.content
        
        # Dividir respuesta si incluye el separador
        if "|||" in response_text:
            messages = [msg.strip() for msg in response_text.split("|||") if msg.strip()]
        else:
            messages = self.split_response_into_messages(response_text, 3800)
        
        return messages

    async def _handle_product_search(self, db: Session, analysis: Dict, message_text: str) -> List[str]:
        """
        Maneja b√∫squedas generales de productos con respuesta conversacional.
        """
        search_terms = analysis.get("search_terms", [])
        
        # Asegurar que search_terms sea una lista
        if search_terms is None:
            search_terms = []
            
        search_query = " ".join(search_terms) if search_terms else message_text
        
        logger.info(f"Realizando b√∫squeda general de productos para: {search_query}")
        
        # B√∫squeda sem√°ntica usando ProductService
        search_results = await self.product_service.search_products(
            db=db,
            query_text=search_query,
            top_k=6  # M√°s productos para mejor selecci√≥n
        )
        
        main_products = search_results.get("main_results", [])
        related_products = search_results.get("related_results", [])
        
        if not main_products and not related_products:
            return [
                f"üîç Busqu√© productos relacionados con: *{search_query}*",
                "‚ùå No encontr√© productos espec√≠ficos para esa b√∫squeda.\n\nüí° Puedes intentar con t√©rminos m√°s generales como:\n‚Ä¢ 'tubos'\n‚Ä¢ 'v√°lvulas'\n‚Ä¢ 'conectores'\n‚Ä¢ 'herramientas'\n‚Ä¢ 'tornillos'\n‚Ä¢ 'pinturas'"
            ]
        
        messages = []
        
        # Mensaje inicial m√°s conversacional
        initial_message = f"üîç ¬°Perfecto! Encontr√© varios productos para tu b√∫squeda de *{search_query}*.\n\n‚ú® Aqu√≠ est√°n las mejores opciones:"
        messages.append(initial_message)
        
        # Mostrar productos principales de forma m√°s conversacional
        if main_products:
            for i, product in enumerate(main_products, 1):
                product_message = f"*{i}. {product.name}*\n"
                
                if product.description:
                    desc = product.description[:120] + "..." if len(product.description) > 120 else product.description
                    product_message += f"üìù {desc}\n\n"
                
                product_message += f"üí∞ Precio: *${product.price:,.0f}*\n"
                
                if product.category:
                    product_message += f"üè∑Ô∏è {product.category.name}\n"
                
                if hasattr(product, 'brand') and product.brand:
                    product_message += f"üè≠ {product.brand}\n"
                
                # Agregar especificaciones destacadas si existen
                if product.spec_json:
                    specs_preview = []
                    for key, value in list(product.spec_json.items())[:2]:  # Solo las primeras 2 specs
                        specs_preview.append(f"‚Ä¢ {key}: {value}")
                    if specs_preview:
                        product_message += f"‚öôÔ∏è Especificaciones:\n" + "\n".join(specs_preview) + "\n"
                
                messages.append(product_message)
        
        # Mostrar productos relacionados m√°s brevemente
        if related_products:
            related_message = "üîó *Tambi√©n podr√≠an interesarte:*\n\n"
            for product in related_products:
                related_message += f"‚Ä¢ *{product.name}* - ${product.price:,.0f}\n"
            messages.append(related_message)
        
        # Mensaje final conversacional
        follow_up = "üí¨ ¬øTe interesa conocer m√°s detalles de alguno de estos productos?\n\nüîç Solo menciona el nombre del producto y te dar√© informaci√≥n t√©cnica completa."
        messages.append(follow_up)
        
        return messages

    async def _handle_technical_question(self, db: Session, analysis: Dict, message_text: str) -> List[str]:
        """
        Maneja preguntas t√©cnicas espec√≠ficas sobre especificaciones de productos.
        
        Esta funci√≥n analiza preguntas t√©cnicas y trata de proporcionar respuestas
        precisas basadas en las especificaciones de productos relevantes.
        """
        search_terms = analysis.get("search_terms", [])
        technical_aspect = analysis.get("technical_aspect", "")
        
        # Asegurar que search_terms sea una lista
        if search_terms is None:
            search_terms = []
        
        # Si no hay t√©rminos de b√∫squeda espec√≠ficos, extraer del mensaje
        if not search_terms:
            search_terms = message_text.split()
        
        search_query = " ".join(search_terms) if search_terms else message_text
        
        logger.info(f"Analizando pregunta t√©cnica: {technical_aspect} para b√∫squeda: {search_query}")
        
        # Buscar productos relevantes para la pregunta t√©cnica
        search_results = await self.product_service.search_products(
            db=db,
            query_text=search_query,
            top_k=3  # Pocos productos pero relevantes
        )
        
        main_products = search_results.get("main_results", [])
        
        if not main_products:
            return [
                f"üîç Busqu√© informaci√≥n t√©cnica sobre: *{search_query}*",
                "‚ùå No encontr√© productos con especificaciones t√©cnicas espec√≠ficas para esa consulta.\n\nüí° ¬øPodr√≠as ser m√°s espec√≠fico sobre el producto que te interesa?"
            ]
        
        # Analizar especificaciones t√©cnicas con IA
        technical_analysis = await self._analyze_technical_specifications(
            main_products, 
            technical_aspect or message_text, 
            message_text
        )
        
        # Dividir respuesta t√©cnica en mensajes naturales
        messages = self.split_response_into_messages(technical_analysis, 3800)
        
        return messages

    async def _handle_conversational_response(self, message_text: str, analysis: Dict) -> List[str]:
        """
        Maneja respuestas conversacionales generales con personalidad de vendedor experto.
        """
        logger.info(f"Generando respuesta conversacional para: {analysis.get('user_intent_description', 'unknown')}")
        
        conversation_prompt = f"""
Eres un asistente especializado de Macroferro, una empresa que vende productos industriales de alta calidad.

El usuario te escribi√≥: "{message_text}"

CONTEXTO DE MACROFERRO:
- Vendemos productos industriales: tuber√≠as, v√°lvulas, herramientas el√©ctricas, conectores, tornillos, pinturas industriales, etc.
- Atendemos principalmente clientes profesionales (electricistas, plomeros, constructores, talleres)
- Tenemos un cat√°logo amplio con especificaciones t√©cnicas detalladas
- Brindamos asesor√≠a t√©cnica especializada
- Somos expertos en compatibilidad y aplicaciones de productos

TU PERSONALIDAD:
- Profesional pero amigable y conversacional
- Experto t√©cnico que conoce bien los productos
- Orientado a ayudar y resolver problemas
- Proactivo en sugerir soluciones

INSTRUCCIONES:
1. Responde de manera natural y conversacional
2. Si es un saludo, sal√∫dalo cordialmente y pres√©ntate como experto en productos industriales
3. Si pregunta sobre la empresa, comparte informaci√≥n relevante
4. Si la consulta es vaga, haz preguntas espec√≠ficas para ayudar mejor
5. Siempre orienta hacia productos espec√≠ficos cuando sea posible
6. Usa emojis apropiados para hacer la conversaci√≥n m√°s amigable
7. Divide en 2-3 mensajes si es necesario (separa con "|||")
8. Invita a hacer consultas espec√≠ficas sobre productos
9. Mant√©n un tono experto pero accesible

Responde de manera √∫til y orientada a la acci√≥n.
"""
        
        if not self.openai_client:
            # Respuesta est√°tica si no hay OpenAI configurado
            if any(greeting in message_text.lower() for greeting in ['hola', 'buenos', 'buenas', 'hello', 'hi', 'saludos']):
                return [
                    "¬°Hola! üëã Soy el asistente t√©cnico de Macroferro.",
                    "üîß Estoy aqu√≠ para ayudarte con informaci√≥n sobre nuestros productos industriales: tuber√≠as, v√°lvulas, herramientas, conectores, pinturas y m√°s.\n\nüí¨ ¬øEn qu√© puedo ayudarte hoy?"
                ]
            else:
                return [
                    "üëã ¬°Hola! Soy el asistente de Macroferro.",
                    "üîç Puedo ayudarte a encontrar productos industriales y responder preguntas t√©cnicas.\n\nüí° Prueba pregunt√°ndome por alg√∫n producto espec√≠fico o tipo de material que necesites."
                ]
        
        try:
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "user", "content": conversation_prompt}],
                temperature=0.8,    # Temperatura m√°s alta para conversaci√≥n natural
                max_tokens=500,
                timeout=15.0
            )
            
            response_text = response.choices[0].message.content
            
            # Dividir si incluye separador
            if "|||" in response_text:
                messages = [msg.strip() for msg in response_text.split("|||") if msg.strip()]
            else:
                messages = self.split_response_into_messages(response_text, 3800)
            
            return messages
            
        except Exception as e:
            logger.error(f"Error generando respuesta conversacional: {e}")
            return [
                "üëã ¬°Hola! Soy el asistente de Macroferro.",
                "üîç Estoy aqu√≠ para ayudarte con informaci√≥n sobre productos industriales.\n\nüí¨ ¬øEn qu√© puedo ayudarte?"
            ]

    # ========================================
    # AN√ÅLISIS T√âCNICO DE ESPECIFICACIONES
    # ========================================
    
    async def _analyze_technical_specifications(
        self, 
        products: List, 
        technical_aspect: str, 
        original_question: str
    ) -> str:
        """
        Analiza las especificaciones t√©cnicas de productos y genera respuesta inteligente.
        
        Esta funci√≥n examina el campo spec_json de cada producto para encontrar
        informaci√≥n t√©cnica relevante y generar respuestas detalladas usando IA.
        
        Args:
            products: Lista de productos relevantes encontrados
            technical_aspect: Aspecto t√©cnico espec√≠fico (di√°metro, presi√≥n, etc.)
            original_question: Pregunta original del usuario para contexto
            
        Returns:
            Respuesta formateada con informaci√≥n t√©cnica detallada
        """
        try:
            # Recopilar informaci√≥n t√©cnica de todos los productos
            technical_info = []
            for product in products:
                product_info = {
                    "name": product.name,
                    "sku": product.sku,
                    "brand": product.brand,
                    "category": product.category.name if product.category else "Sin categor√≠a",
                    "price": float(product.price),
                    "specifications": product.spec_json or {}
                }
                technical_info.append(product_info)
            
            # Crear prompt para an√°lisis t√©cnico con IA
            technical_prompt = f"""
El usuario pregunt√≥: "{original_question}"

Se identific√≥ que busca informaci√≥n sobre: {technical_aspect}

Aqu√≠ est√°n los productos relevantes con sus especificaciones t√©cnicas:

{json.dumps(technical_info, indent=2, ensure_ascii=False)}

Tu tarea es analizar estas especificaciones y responder la pregunta t√©cnica del usuario de manera clara y profesional.

Instrucciones:
1. Busca en las especificaciones (campo "specifications") informaci√≥n relacionada con la pregunta
2. Si encuentras datos relevantes, pres√©ntalos de forma clara y organizada
3. Compara entre productos si hay m√∫ltiples opciones
4. Si no hay informaci√≥n espec√≠fica en las especificaciones, ind√≠calo honestamente
5. Usa formato Markdown para mejor presentaci√≥n
6. Incluye emojis t√©cnicos apropiados (‚öôÔ∏è üìê üîß üíß ‚ö° etc.)
7. Mant√©n un tono profesional pero accesible
8. Si es posible, da recomendaciones basadas en la informaci√≥n disponible

Responde en espa√±ol de manera concisa pero completa.
"""
            
            # Generar respuesta t√©cnica con IA
            response = await self.openai_client.chat.completions.create(
                model="gpt-4o-mini-2024-07-18",
                messages=[{"role": "user", "content": technical_prompt}],
                temperature=0.3,    # Baja temperatura para precisi√≥n t√©cnica
                max_tokens=800,     # M√°s espacio para respuestas t√©cnicas detalladas
                timeout=20.0        # Timeout generoso para an√°lisis complejo
            )
            
            ai_response = response.choices[0].message.content
            
            # Agregar footer con productos analizados
            footer = f"\n\n*üìã Productos analizados:*\n"
            for i, product in enumerate(products, 1):
                footer += f"{i}. {product.name} (SKU: {product.sku})\n"
            
            footer += "\nüí¨ ¬øNecesitas m√°s detalles espec√≠ficos de alg√∫n producto?"
            
            return ai_response + footer
            
        except Exception as e:
            logger.error(f"Error analizando especificaciones t√©cnicas: {e}")
            
            # Fallback: respuesta b√°sica con informaci√≥n disponible
            response_text = f"üîß *Informaci√≥n t√©cnica encontrada:*\n\n"
            
            for i, product in enumerate(products, 1):
                response_text += f"*{i}. {product.name}*\n"
                response_text += f"üì¶ SKU: {product.sku}\n"
                if product.brand:
                    response_text += f"üè≠ Marca: {product.brand}\n"
                if product.category:
                    response_text += f"üè∑Ô∏è Categor√≠a: {product.category.name}\n"
                
                # Mostrar especificaciones si existen
                if product.spec_json:
                    response_text += f"‚öôÔ∏è *Especificaciones disponibles:*\n"
                    for key, value in product.spec_json.items():
                        response_text += f"  ‚Ä¢ {key}: {value}\n"
                else:
                    response_text += f"üìù No hay especificaciones t√©cnicas detalladas disponibles\n"
                
                response_text += "\n"
            
            response_text += "üí¨ Para informaci√≥n t√©cnica m√°s espec√≠fica, puedes contactar directamente con nuestro equipo t√©cnico."
            
            return response_text

    # ========================================
    # CONFIGURACI√ìN DE WEBHOOK
    # ========================================
    
    async def set_webhook(self, webhook_url: str, secret_token: str) -> Dict[str, Any]:
        """
        Configura el webhook de Telegram para recibir actualizaciones en tiempo real.
        
        Esta funci√≥n establece la URL donde Telegram enviar√° todas las actualizaciones
        del bot (mensajes, comandos, etc.) usando el mecanismo de webhook en lugar
        de polling, lo cual es m√°s eficiente para aplicaciones en producci√≥n.
        
        Args:
            webhook_url: URL completa donde Telegram enviar√° las actualizaciones
            secret_token: Token secreto para validar que las actualizaciones vienen de Telegram
            
        Returns:
            Respuesta JSON del API de Telegram confirmando la configuraci√≥n
            
        Consideraciones de seguridad:
        - webhook_url debe usar HTTPS en producci√≥n
        - secret_token debe ser √∫nico y seguro (min 1-256 caracteres)
        - Telegram validar√° el certificado SSL de la URL
        - La URL debe ser p√∫blicamente accesible desde servidores de Telegram
        
        Configuraci√≥n t√≠pica para producci√≥n:
        - webhook_url: "https://api.macroferro.com/api/v1/telegram/webhook"
        - secret_token: Token generado aleatoriamente y guardado en variables de entorno
        
        Ventajas del webhook vs polling:
        - Latencia mucho menor (instant√°neo vs 1-30 segundos)
        - Menor uso de ancho de banda
        - No requiere conexiones persistentes
        - Escalabilidad horizontal mejor
        
        Consideraciones de infraestructura:
        - Requiere HTTPS v√°lido en producci√≥n
        - Load balancer debe enrutar al contenedor correcto
        - Manejo de reintentos si el webhook falla temporalmente
        - Monitoreo de salud del endpoint del webhook
        
        Extensiones futuras:
        - Validaci√≥n autom√°tica del secret_token en el endpoint
        - M√©tricas de latencia y √©xito de webhooks
        - Fallback a polling si webhook falla persistentemente
        - Configuraci√≥n de allowed_updates para filtrar tipos de eventos
        """
        if not self.api_base_url:
            logger.error("Bot token no configurado, no se puede configurar webhook")
            raise ValueError("Telegram bot token not configured")
            
        url = f"{self.api_base_url}/setWebhook"
        payload = {
            "url": webhook_url,
            "secret_token": secret_token,
            # Futuras configuraciones opcionales:
            # "allowed_updates": ["message", "callback_query"],  # Filtrar tipos de eventos
            # "drop_pending_updates": True,  # Limpiar actualizaciones pendientes
            # "max_connections": 100,  # L√≠mite de conexiones concurrentes
        }
        
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(url, json=payload)
                response.raise_for_status()
                
                result = response.json()
                if result.get("ok"):
                    logger.info(f"Webhook configurado exitosamente: {webhook_url}")
                else:
                    logger.error(f"Error configurando webhook: {result}")
                    
                return result
                
        except httpx.TimeoutException as e:
            logger.error(f"Timeout configurando webhook: {e}")
            raise
        except httpx.HTTPStatusError as e:
            logger.error(f"Error HTTP configurando webhook: {e.response.status_code} - {e.response.text}")
            raise
        except Exception as e:
            logger.error(f"Error inesperado configurando webhook: {e}")
            raise

# ========================================
# INSTANCIA SINGLETON DEL SERVICIO
# ========================================

# Instancia √∫nica del servicio para ser usada en toda la aplicaci√≥n
# Se crea solo si el token del bot est√° configurado para evitar errores en desarrollo
telegram_service = TelegramBotService() if settings.telegram_bot_token else None

# ========================================
# EXTENSIONES Y M√âTODOS AUXILIARES FUTUROS
# ========================================

# M√©todos auxiliares que se implementar√≠an en versiones futuras:
#
# async def _validate_user_permissions(self, user_id: int, chat_id: int) -> bool:
#     """Valida permisos del usuario para acceder a funcionalidades espec√≠ficas."""
#     pass
#
# async def _log_user_interaction(self, user_id: int, message_text: str, response_text: str) -> None:
#     """Registra interacciones para an√°lisis de uso y mejora del bot."""
#     pass
#
# async def _get_user_context(self, db: Session, user_id: int) -> Dict[str, Any]:
#     """Obtiene contexto conversacional persistente del usuario."""
#     pass
#
# async def _save_user_context(self, db: Session, user_id: int, context: Dict[str, Any]) -> None:
#     """Guarda contexto conversacional para futuras interacciones."""
#     pass
#
# async def _generate_product_recommendations(self, db: Session, user_id: int) -> List[models.Product]:
#     """Genera recomendaciones personalizadas basadas en historial del usuario."""
#     pass
#
# async def _format_product_details(self, product: models.Product) -> str:
#     """Formatea detalles completos de un producto para visualizaci√≥n rica."""
#     pass
#
# async def _handle_product_inquiry(self, db: Session, product_sku: str, user_id: int) -> str:
#     """Maneja consultas espec√≠ficas sobre un producto (precio, stock, especificaciones)."""
#     pass
#
# async def _send_typing_action(self, chat_id: int) -> None:
#     """Env√≠a acci√≥n de 'escribiendo...' para mejor UX durante procesamiento."""
#     pass
#
# async def _create_inline_keyboard(self, options: List[Dict[str, str]]) -> Dict[str, Any]:
#     """Crea teclado inline con botones para navegaci√≥n interactiva."""
#     pass
#
# async def _handle_callback_query(self, callback_data: str, chat_id: int) -> str:
#     """Procesa respuestas de botones inline del usuario."""
#     pass
#
# async def _validate_webhook_secret(self, request_headers: Dict[str, str]) -> bool:
#     """Valida que el webhook viene realmente de Telegram usando el secret token."""
#     pass
#
# async def _retry_failed_message(self, chat_id: int, text: str, max_retries: int = 3) -> bool:
#     """Reintenta env√≠o de mensajes fallidos con backoff exponencial."""
#     pass 